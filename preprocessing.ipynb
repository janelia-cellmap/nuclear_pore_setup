{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Rasterized Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as nmp # it's called nmp so we can not confused it with np\n",
    "import zarr\n",
    "\n",
    "def in_cylinder(end_1, end_2, radius):\n",
    "    # code borrowed from https://stackoverflow.com/questions/56463412/distance-from-a-point-to-a-line-segment-in-3d-python\n",
    "    # getting the normalized tangent vector between the points\n",
    "    d = nmp.divide(end_2 - end_1, nmp.linalg.norm(end_2 - end_1)) \n",
    "\n",
    "    # finding min and max to get all possible voxels that can fit inside the hypothetical cylinder there\n",
    "    mins = nmp.floor(nmp.minimum(end_1,end_2)).astype(int)-(nmp.ceil(radius).astype(int)+1) #1s for padding\n",
    "    maxs = nmp.ceil(nmp.maximum(end_1,end_2)).astype(int) +(nmp.ceil(radius).astype(int)+1)\n",
    "    \n",
    "    # now we get list of all the possible points using the mins and maxes (in form of x, y, z)\n",
    "    x,y,z = [list(range(mins[i],maxs[i]+1,1)) for i in range(3)]\n",
    "    p = nmp.array(nmp.meshgrid(x, y,z)).T.reshape((-1,3)) # puts together all the combinations of x y and z to actually get all possible points\n",
    "\n",
    "    # signed parallel distance components\n",
    "    # makes sure points aren't out of range of end points\n",
    "    # dot product creates 2 parallel lines from the end points, so limits search to points between those lines (aka within end points)\n",
    "    # negative dot product = between the two values\n",
    "    # positive dot product = not between the values, so we toss those\n",
    "    s = nmp.dot(end_1 - p, d) # the dot product of endpt 1 - point p (so a vector from endpt1 to p)\n",
    "    t = nmp.dot(p - end_2, d) # the dot product of point p - endpt 2 (so a vector from endpt2 to p)\n",
    "\n",
    "    # clamped parallel distance\n",
    "    # now thats its limited to between end points, checks if the point is within the cylinder's radius\n",
    "    # calculates distance from p to the center of cylinder\n",
    "    # if distance < radius that we want, then voxel is inside np\n",
    "    h = nmp.maximum.reduce([s, t, nmp.zeros_like(s)])\n",
    "    # perpendicular distance component\n",
    "    c = nmp.linalg.norm(nmp.cross(p - end_1, d),axis=1)\n",
    "    \n",
    "    # so if the conditions are right, then we know the voxel is inside the cylinder!\n",
    "    is_in_cylinder = (h==0) & (c<=radius)\n",
    "    return set(map(tuple, p[is_in_cylinder]))\n",
    "\n",
    "\n",
    "### coding sequence actually begins here ###\n",
    "# opens file with the np annotation data\n",
    "zarr_file = zarr.open(f\"/nrs/cellmap/data/jrc_mus-liver-zon-1/jrc_mus-liver-zon-1.n5\", mode=\"r\")\n",
    "dataset = \"em/fibsem-uint8/s0\"\n",
    "resolution = nmp.array(zarr_file[dataset].attrs.asdict()[\"transform\"][\"scale\"]) # either 4x4x4 nm or 8x8x8 nm\n",
    "\n",
    "# https://cell-map.slack.com/archives/C04N9JUFQK1/p1683733456153269\n",
    "df = pd.read_csv(\"annotations_20230606_155330.csv\")\n",
    "np_starts = nmp.array([df[\"start x (nm)\"], df[\"start y (nm)\"], df[\"start z (nm)\"]]).T/resolution # getting start points data in voxels (divide by res)\n",
    "np_ends = nmp.array([df[\"end x (nm)\"], df[\"end y (nm)\"], df[\"end z (nm)\"]]).T/resolution # getting end points data in voxels (divide by res)\n",
    "np_centers = list(map(tuple,nmp.round(((np_starts+np_ends)*resolution/2)).astype(int))) # calculate centers (in nm)\n",
    "\n",
    "# densely annotated validation region:\n",
    "offset = nmp.array([11020, 9900, 7750]) # where validation region is located\n",
    "dimensions = nmp.array([100, 150, 210]) # how big the validation space is"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can find which points are in cylinder, we can do this for all annotations and concatenate, then we can write out the n5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [00:00<00:00, 403.44it/s]\n",
      "100%|██████████| 243/243 [00:49<00:00,  4.93it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "from numcodecs.gzip import GZip\n",
    "import zarr\n",
    "\n",
    "# get all np voxels and all overlapping/intersecting voxels between multiple np. np = nuclear pore, not to be confused with nmp numpy\n",
    "all_np_voxels_set = set()\n",
    "intersection_voxels_set = set()\n",
    "for np_start,np_end in tqdm(zip(np_starts,np_ends),total=len(np_starts)):\n",
    "    #goes thru each cylinder and adds voxels in current cylinder to all_np\n",
    "    voxels_in_cylinder = in_cylinder(np_start,np_end,radius=7.5)\n",
    "    #then look thru and see if there are any of them already in all_np (if so, they are intersecting) \n",
    "    intersection_voxels_set.update(all_np_voxels_set.intersection(voxels_in_cylinder))\n",
    "    all_np_voxels_set.update(voxels_in_cylinder)\n",
    "\n",
    "# repeat but now will write out the relevant voxels with appropriate np id (do not count intersecting ones aka remove overlap)\n",
    "store = zarr.N5Store(\"/nrs/cellmap/nguyenh3/cellmap/np_preprocess/jrc_mus-liver-zon-1.n5\")\n",
    "# creating dataset\n",
    "zarr_root = zarr.group(store=store)\n",
    "ds = zarr_root.create_dataset(\n",
    "        overwrite=True,\n",
    "        name=\"nuclearpores_as_cylinders\",\n",
    "        dtype='u2', #unsigned int 2 bytes\n",
    "        shape=zarr_file[dataset].shape, #dimensions of shape\n",
    "        chunks=128, # size of chunk in each dimension (we like powers of 2) we also like it moderately small ~100\n",
    "        write_empty_chunks=False, #if chunk of data (where u chunk it in x/y/z) doesnt contain anything, then this won't write it out\n",
    "        compressor=GZip(level=6), #standard\n",
    "    )\n",
    "\n",
    "# attributes of the dataset\n",
    "attributes = ds.attrs \n",
    "attributes[\"pixelResolution\"] = { #set pixel res\n",
    "    \"dimensions\": 3 * [8],\n",
    "    \"unit\": \"nm\",\n",
    "}\n",
    "\n",
    "np_id = 1 #to number each one\n",
    "all_np_voxels_set -= intersection_voxels_set # get rid of all the intersecting ones\n",
    "# now we do what we did earlier (see how many voxels in the cylinder and subtract intersecting ones)\n",
    "for np_start,np_end in tqdm(zip(np_starts,np_ends),total=len(np_starts)):\n",
    "    voxels_in_cylinder = in_cylinder(np_start,np_end,radius=7.5) - intersection_voxels_set # get voxels in the cylinder minus intersecting ones\n",
    "    if len(voxels_in_cylinder)>0:\n",
    "        voxels_in_cylinder = nmp.array(list(voxels_in_cylinder)) # list of all voxels in the cylinder\n",
    "        ds[voxels_in_cylinder[:,2],voxels_in_cylinder[:,1],voxels_in_cylinder[:,0]] = np_id # write out data to actual n5 data file\n",
    "        np_id +=1 #increment ID when going to next np \n",
    "    else:\n",
    "        raise Exception(f\"Empty nuclear pore {np_starts}-{np_ends}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing intersections from data, network needs to know it shouldnt train there, so set intersection voxels to 0. The mask is where we don't want network to train (1 everywhere else, 0 where there are intersecting voxels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Use the same path and make/open the masks zarr file\n",
    "#zarr_file = zarr.open(f\"/nrs/cellmap/nguyenh3/cellmap/np_preprocess/jrc_mus-liver-zon-1/jrc_mus-liver-zon-1.n5\", mode=\"r\")\n",
    "zarr_path = \"/nrs/cellmap/nguyenh3/cellmap/np_preprocess/masks.zarr\"\n",
    "if not os.path.exists(zarr_path):\n",
    "    zarr_root = zarr.open(zarr_path, mode='w')\n",
    "# creating dataset for the mask\n",
    "ds = zarr_root.create_dataset(\n",
    "        overwrite=True,\n",
    "        name=\"jrc_mus-liver-zon-1\",\n",
    "        dtype='u1',\n",
    "        fill_value = 1, # we can set fill w/ zarr. with mask we want everything to be 1 so fill with 1 automatically \n",
    "        shape=zarr_file[dataset].shape,\n",
    "        chunks=128, \n",
    "        write_empty_chunks=False,\n",
    "        compressor=GZip(level=6),\n",
    "    )\n",
    "attributes = ds.attrs\n",
    "attributes[\"pixelResolution\"] = {\n",
    "    \"dimensions\": 3 * [8],\n",
    "    \"unit\": \"nm\",\n",
    "}\n",
    "\n",
    "# \n",
    "intersection_voxels = nmp.array(list(intersection_voxels_set))\n",
    "ds[intersection_voxels[:,2],intersection_voxels[:,1],intersection_voxels[:,0]] = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numcodecs.gzip import GZip\n",
    "\n",
    "# taking the NP data set as cylinders and cropping it so we take a portion of the data for validation\n",
    "zarr_file = zarr.open(f\"/nrs/cellmap/nguyenh3/cellmap/np_preprocess/jrc_mus-liver-zon-1.n5\", mode=\"r\")\n",
    "nuclearpores_as_cylinders = zarr_file[\"nuclearpores_as_cylinders\"]\n",
    "validation_crop = nuclearpores_as_cylinders[offset[2]:offset[2]+dimensions[2],\n",
    "                                             offset[1]:offset[1]+dimensions[1],\n",
    "                                             offset[0]:offset[0]+dimensions[0]]\n",
    "\n",
    "store = zarr.N5Store(\"/nrs/cellmap/nguyenh3/cellmap/np_preprocess/jrc_mus-liver-zon-1.n5\")\n",
    "zarr_root = zarr.group(store=store)\n",
    "ds = zarr_root.create_dataset(\n",
    "        overwrite=True,\n",
    "        name=\"validation_crop\",\n",
    "        data=validation_crop,\n",
    "        dtype='u2',\n",
    "        chunks=128,\n",
    "        write_empty_chunks=False,\n",
    "        compressor=GZip(level=6),\n",
    "    )\n",
    "attributes = ds.attrs\n",
    "attributes[\"pixelResolution\"] = {\n",
    "    \"dimensions\": 3 * [8],\n",
    "    \"unit\": \"nm\",\n",
    "}\n",
    "attributes[\"offset\"] = list(offset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get nuclear pores that are not in validation crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [00:00<00:00, 402.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(216, 243)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting all training data set\n",
    "updated_np_centers = []\n",
    "removed_centers = []\n",
    "# loop over all nuclear pores (sees which voxels are inside it) then checks if its in val crop,\n",
    "# if they are then ignores it\n",
    "for np_start,np_end,np_center in tqdm(zip(np_starts,np_ends,np_centers),total=len(np_starts)):\n",
    "    voxels_in_cylinder = in_cylinder(np_start,np_end,radius=7.5)\n",
    "    voxels_in_cylinder = nmp.array(list(voxels_in_cylinder))\n",
    "    if ~nmp.any([(voxels_in_cylinder[:,0]>=offset[0]) & (voxels_in_cylinder[:,0]<=offset[0]+dimensions[0])\n",
    "                & (voxels_in_cylinder[:,1]>=offset[1]) & (voxels_in_cylinder[:,1]<=offset[1]+dimensions[1])\n",
    "                & (voxels_in_cylinder[:,2]>=offset[2]) & (voxels_in_cylinder[:,2]<=offset[2]+dimensions[2])]):\n",
    "        updated_np_centers.append(np_center)\n",
    "    else:\n",
    "        removed_centers.append(np_center)\n",
    "len(updated_np_centers),len(np_centers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stopped before here 6/6/23\n",
    "rather than have training centered exactly at nuclear pore centers, use the centers as a reference for choosing a random location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [00:00<00:00, 10640.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11046.6796875  10060.16503906  7802.078125  ] [11043.390625  10059.1640625  7799.421875 ]\n",
      "[11045.03808594 10024.30273438  7975.15625   ] [11040.4609375  10025.68652344  7975.85058594]\n",
      "[11070.54101562 10056.00390625  7735.15234375] [11066.54101562 10056.00292969  7735.15234375]\n",
      "[11105.37109375  9892.10546875  7889.21044922] [11102.01757812  9889.75878906  7890.49511719]\n",
      "[11134.03417969  9909.51757812  7738.98876953] [11130.5234375   9908.24414063  7738.65820312]\n",
      "[11133.42871094  9893.18359375  7756.02392578] [11136.97363281  9893.97558594  7757.34375   ]\n",
      "[11097.71582031  9890.43847656  7964.86523438] [11101.05371094  9893.02636719  7963.08740234]\n",
      "[11105.91113281  9890.109375    7926.36230469] [11102.61035156  9883.04003906  7929.12988281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(208, 243)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# makes sure center is not part of validation set\n",
    "def center_is_valid(center, edge_length):\n",
    "    if nmp.all( (center+edge_length) >= offset) and nmp.all( (center-edge_length) <= (offset+dimensions) ):\n",
    "        # then it overlaps validation\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# checks so that \n",
    "def too_close_to_validation(np_start, np_end, edge_length):\n",
    "    # either the start or end will be furthest from the box\n",
    "    start_distance = nmp.linalg.norm( nmp.maximum.reduce([offset - np_start, nmp.zeros_like(np_start), np_start-(offset+dimensions)]) )\n",
    "    end_distance = nmp.linalg.norm( nmp.maximum.reduce([offset - np_end, nmp.zeros_like(np_end), np_end-(offset+dimensions)]) )\n",
    "    return nmp.maximum(start_distance, end_distance) <= edge_length\n",
    "\n",
    "# shifts everything so we can grab more context\n",
    "pseudorandom_training_centers = []\n",
    "for np_start,np_end in tqdm(zip(np_starts,np_ends),total=len(np_starts)):\n",
    "    # ultimately seems to predict on 36x36x36 region, so we need to make sure this doesn't overlap with validation\n",
    "    # lets just shift by at most +/-10 in any dimension for the center to help ensure that a non-neglible part of the rasterization, and original annotation, are included in a box centered at that region\n",
    "    max_shift = 18\n",
    "    edge_length = 18+1 # add one for padding since we round later down\n",
    "    # first find a random coordinate along the annotation. this will be included within the box\n",
    "\n",
    "    # now find a valid center\n",
    "    if not too_close_to_validation(np_start,np_end, edge_length):\n",
    "        random_coordinate_along_annotation = np_start+(np_end-np_start)*nmp.random.rand()\n",
    "        center = random_coordinate_along_annotation + nmp.random.randint(low=-max_shift,high=max_shift,size=3)\n",
    "        while not center_is_valid(center, edge_length):\n",
    "            random_coordinate_along_annotation = np_start+(np_end-np_start)*nmp.random.rand()\n",
    "            center = random_coordinate_along_annotation + nmp.random.randint(low=-max_shift,high=max_shift,size=3)\n",
    "        pseudorandom_training_centers.append(tuple(nmp.round(center*resolution).astype(int)))\n",
    "    else:\n",
    "        c = nmp.round(((np_start+np_end)*resolution/2)).astype(int)\n",
    "        if tuple(c) not in removed_centers:\n",
    "            print(np_start,np_end)\n",
    "len(pseudorandom_training_centers),len(np_starts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random testing is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.88449745048757"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_coordinate_along_annotation = NP_start+(NP_end-NP_start)*np.random.rand()\n",
    "np.mean(np.linalg.norm((NP_starts[:50]+NP_ends[:50])/2-np.array(pseudorandom_training_centers[:50])/8,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([11225.375, 10457.5  ,  7514.75 ]),\n",
       " array([11238.5  , 10461.125,  7506.25 ]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(updated_NP_centers[5])/8,np.array(pseudorandom_training_centers[5])/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11283.93419863  9680.29622955  7965.96543411] [11290.10449219  9681.64941406  7966.13183594] [11282.69921875  9680.02539062  7965.93212891] [11291.93419863  9693.29622955  7966.96543411]\n"
     ]
    }
   ],
   "source": [
    "random_coordinate_along_annotation\n",
    "NP_start+(NP_end-NP_start)*np.random.rand()\n",
    "print(random_coordinate_along_annotation, NP_start, NP_end, random_coordinate_along_annotation + np.random.randint(low=-max_shift,high=max_shift,size=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([11286.375,  9680.875,  7966.   ]), array([11297. ,  9684.5,  7955. ]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NP_centers[-1]/resolution,pseudorandom_training_centers[-1]/resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (NP_start\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m) \u001b[39mand\u001b[39;00m (NP_end\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "(NP_start>0) and (NP_end>0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dacapo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.experiments.architectures import CNNectomeUNetConfig\n",
    "from dacapo.experiments.trainers import GunpowderTrainerConfig\n",
    "from dacapo.experiments.trainers.gp_augments import ElasticAugmentConfig,IntensityAugmentConfig\n",
    "from dacapo.experiments.tasks import AffinitiesTaskConfig\n",
    "from funlib.geometry.coordinate import Coordinate\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dacapo -> makes it easier to use pytorch\n",
    "\n",
    "trainer_config = GunpowderTrainerConfig(\n",
    "        name=\"default_v2\",\n",
    "        batch_size=2,#how many it takes in at once before updating\n",
    "        learning_rate=0.0001, \n",
    "        augments=[ #augments add more variation so it can learn more different things (makes more generic)\n",
    "            ElasticAugmentConfig(\n",
    "                control_point_spacing=(100, 100, 100),\n",
    "                control_point_displacement_sigma=(10.0, 10.0, 10.0),\n",
    "                rotation_interval=(0, math.pi / 2.0),\n",
    "                subsample=8,\n",
    "                uniform_3d_rotation=True,\n",
    "            ),\n",
    "            IntensityAugmentConfig(\n",
    "                scale=(0.7, 1.3),\n",
    "                shift=(-0.2, 0.2),\n",
    "                clip=True,\n",
    "            ),\n",
    "        ],\n",
    "        clip_raw=True,\n",
    "        num_data_fetchers=20,\n",
    "        snapshot_interval=10000,\n",
    "        min_masked=0.05,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config = AffinitiesTaskConfig(\n",
    "\n",
    "    # task that we want is to predict affinities\n",
    "    # 19 total predicted channels\n",
    "    # 9 neighborhood channels + 10 local shape descriptors\n",
    "    # idk where the local shape descriptors are but its not here\n",
    "    # higher affinity = i think i am connected to that voxel to the one space z from me (1, 0, 0) = 2. the same thing with the others but 3 or 9 \n",
    "    # voxels away from me\n",
    "    # neighborhood \n",
    "            name=f\"3d_lsdaffs\",\n",
    "            neighborhood=[\n",
    "                (1, 0, 0),\n",
    "                (0, 1, 0),\n",
    "                (0, 0, 1),\n",
    "                (3, 0, 0),\n",
    "                (0, 3, 0),\n",
    "                (0, 0, 3),\n",
    "                (9, 0, 0),\n",
    "                (0, 9, 0),\n",
    "                (0, 0, 9),\n",
    "            ],\n",
    "            lsds=True, # do the lsds task (local shape descriptors)\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had an issue where, by default, I created the rasterization at the same resolution as the raw data. But the default architecture (with the upsampling layer `upsample_factors`) expects it to be at 2x the resolution including mask and validation. This resulted in an error when submitting. Since we don't really care about a higher res (at the moment), we can just comment out the upsampling layer (`constant_upsample` and `upsample_factors`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_config = CNNectomeUNetConfig( #here is the actual network architecture (a u-net) the cnnectome\n",
    "        name=\"upsample-unet\",\n",
    "        input_shape=Coordinate(216, 216, 216), # size/shape of input \n",
    "        eval_shape_increase=Coordinate(72, 72, 72),\n",
    "        fmaps_in=1,\n",
    "        num_fmaps=12,\n",
    "        fmaps_out=72,\n",
    "        fmap_inc_factor=6,\n",
    "        downsample_factors=[(2, 2, 2), (3, 3, 3), (3, 3, 3)], # in addition to convolutional layers, also down samples to make it smaller \n",
    "        # and then gets bigger later when upsampling\n",
    "        #constant_upsample=True,\n",
    "        #upsample_factors=[(2, 2, 2)],\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasplit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVERYTHING MUST BE IN Z,Y,X AND NM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use centers\n",
    "from pathlib import Path\n",
    "from dacapo.experiments.datasplits.datasets.arrays import (\n",
    "    ZarrArrayConfig,\n",
    "    IntensitiesArrayConfig,\n",
    "    CropArrayConfig,\n",
    ")\n",
    "from dacapo.experiments.datasplits.datasets import RawGTDatasetConfig\n",
    "from dacapo.experiments.datasplits import TrainValidateDataSplitConfig\n",
    "from funlib.geometry import Roi\n",
    "\n",
    "# lets look at raw data (input for network)\n",
    "raw_config = ZarrArrayConfig(\n",
    "    name = \"raw\",\n",
    "    file_name=Path(\"/nrs/stern/em_data/jrc_22ak351-leaf-3m/jrc_22ak351-leaf-3m.n5\"),\n",
    "    dataset=\"em/fibsem-uint8/s0\",\n",
    ")\n",
    "\n",
    "# everything is rescaled between 0 and 1, just makes sure u set everytnhing in place with mins/maxes\n",
    "# We get an error without this, and will suggests having it as such https://cell-map.slack.com/archives/D02KBQ990ER/p1683762491204909\n",
    "raw_config = IntensitiesArrayConfig(name=\"raw\", source_array_config = raw_config, min=0, max=255)\n",
    "\n",
    "# ground truth = actual data annotated\n",
    "gt_config = ZarrArrayConfig(\n",
    "    name=\"nuclearpores\", \n",
    "    file_name=Path(\"/nrs/cellmap/ackermand/cellmap/leaf-gall/jrc_22ak351-leaf-3m.n5\"), \n",
    "    dataset=\"nuclearpores_as_cylinders\"\n",
    ")\n",
    "\n",
    "# mask out regions of overlapping nuclear pores\n",
    "# \n",
    "mask_config = ZarrArrayConfig(\n",
    "    name=\"mask\", \n",
    "    file_name=Path(\"/nrs/cellmap/ackermand/cellmap/leaf-gall/masks.zarr\"), \n",
    "    dataset=\"jrc_22ak351-leaf-3m\"\n",
    ")\n",
    "\n",
    "# could do validation as a file\n",
    "# val_gt_config = ZarrArrayConfig(\n",
    "#     name=\"nuclearpores\", file_name=\"/path/to/data.zarr\", dataset=\"labels_val\"\n",
    "# )\n",
    "\n",
    "# NOTE: Everything has to be in z,y,x cries\n",
    "# multiply by resolution to go from nm to pixels\n",
    "validation_roi = Roi(offset[::-1]*resolution, dimensions[::-1]*resolution)\n",
    "val_gt_config = CropArrayConfig(\n",
    "    \"val_gt\", source_array_config=gt_config, roi=validation_roi\n",
    "    # the ground truth config same as source for val\n",
    "    # we just are specifying the region of interest (roi)\n",
    "    # has the offset and dimensions\n",
    "    # instead of writing out the crop (we did it anyway) just pass in region of interest corresponding with val region\n",
    "    # the only reason we wrote out the crop earlier is to visualize easier\n",
    ")\n",
    "\n",
    "# now training data has raw data, unwanted stuff is masked, coordinates of the centers as the sample pts\n",
    "training_data_config = RawGTDatasetConfig(\n",
    "    \"train\",\n",
    "    raw_config = raw_config,\n",
    "    gt_config = gt_config,\n",
    "    sample_points = [Coordinate(NP_center[::-1]) for NP_center in updated_NP_centers],#[Coordinate((29229*8,1862*8,7439*8))], #\n",
    "    mask_config = mask_config\n",
    ")\n",
    "\n",
    "# same with val data config (pass in the val config) only difference is we specific the ROI for val data\n",
    "validation_data_config = RawGTDatasetConfig(\"val\", raw_config = raw_config, gt_config=val_gt_config, mask_config=mask_config)\n",
    "\n",
    "# finally specifying which one is the train and which is the validating data set\n",
    "datasplit_config = TrainValidateDataSplitConfig(\n",
    "    name=\"nuclearpores\", train_configs=[training_data_config], validate_configs=[validation_data_config]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pseudorandom centers\n",
    "# same thing just using different centers\n",
    "\n",
    "from pathlib import Path\n",
    "from dacapo.experiments.datasplits.datasets.arrays import (\n",
    "    ZarrArrayConfig,\n",
    "    IntensitiesArrayConfig,\n",
    "    CropArrayConfig,\n",
    ")\n",
    "from dacapo.experiments.datasplits.datasets import RawGTDatasetConfig\n",
    "from dacapo.experiments.datasplits import TrainValidateDataSplitConfig\n",
    "from funlib.geometry import Roi\n",
    "\n",
    "raw_config = ZarrArrayConfig(\n",
    "    name = \"raw\",\n",
    "    file_name=Path(\"/nrs/stern/em_data/jrc_22ak351-leaf-3m/jrc_22ak351-leaf-3m.n5\"),\n",
    "    dataset=\"em/fibsem-uint8/s0\",\n",
    ")\n",
    "# We get an error without this, and will suggests having it as such https://cell-map.slack.com/archives/D02KBQ990ER/p1683762491204909\n",
    "raw_config = IntensitiesArrayConfig(name=\"raw\", source_array_config = raw_config, min=0, max=255)\n",
    "\n",
    "gt_config = ZarrArrayConfig(\n",
    "    name=\"nuclearpores\", \n",
    "    file_name=Path(\"/nrs/cellmap/ackermand/cellmap/leaf-gall/jrc_22ak351-leaf-3m.n5\"), \n",
    "    dataset=\"nuclearpores_as_cylinders\"\n",
    ")\n",
    "\n",
    "# mask out regions of overlapping nuclear pores\n",
    "mask_config = ZarrArrayConfig(\n",
    "    name=\"mask\", \n",
    "    file_name=Path(\"/nrs/cellmap/ackermand/cellmap/leaf-gall/masks.zarr\"), \n",
    "    dataset=\"jrc_22ak351-leaf-3m\"\n",
    ")\n",
    "\n",
    "# could do validation as a file\n",
    "# val_gt_config = ZarrArrayConfig(\n",
    "#     name=\"nuclearpores\", file_name=\"/path/to/data.zarr\", dataset=\"labels_val\"\n",
    "# )\n",
    "\n",
    "# NOTE: Everything has to be in z,y,x\n",
    "validation_roi = Roi(offset[::-1]*resolution, dimensions[::-1]*resolution)\n",
    "val_gt_config = CropArrayConfig(\n",
    "    \"val_gt\", source_array_config=gt_config, roi=validation_roi\n",
    ")\n",
    "training_data_config = RawGTDatasetConfig(\n",
    "    f\"train_pseudorandom_training_centers_maxshift_{max_shift}\",\n",
    "    raw_config = raw_config,\n",
    "    gt_config = gt_config,\n",
    "    sample_points = [Coordinate(pseudorandom_training_center[::-1]) for pseudorandom_training_center in pseudorandom_training_centers],#[Coordinate((29229*8,1862*8,7439*8))], #\n",
    "    mask_config = mask_config\n",
    ")\n",
    "validation_data_config = RawGTDatasetConfig(\"val\", raw_config = raw_config, gt_config=val_gt_config, mask_config=mask_config)\n",
    "datasplit_config = TrainValidateDataSplitConfig(\n",
    "    name=f\"nuclearpores_pseudorandom_training_centers_maxshift_{max_shift}\", train_configs=[training_data_config], validate_configs=[validation_data_config]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.experiments import RunConfig\n",
    "from dacapo.experiments.starts import StartConfig\n",
    "from dacapo.store.create_store import create_config_store\n",
    "config_store = create_config_store()\n",
    "\n",
    "start_config = StartConfig(\"setup04\", \"best\") # using a pretrained set (called best) and just fine tuning the weights from there\n",
    "iterations = 200000\n",
    "validation_interval = 5000 # every 5000, validate and check how its doing and update\n",
    "repetitions = 2 # do the validation twice wch time\n",
    "for i in range(repetitions): #NOTE: Here I am redoing with 2 and 3 becuase i think something happened with validation since i didnt reset the validation scores. ultimately this would probably be fine since eventually lower scores would be reached, but initiailly is giving weird results\n",
    "    run_config = RunConfig( # this is what we actualaly running on the cluster\n",
    "        name=(\"_\").join(\n",
    "            [\n",
    "                \"scratch\" if start_config is None else \"finetuned\",\n",
    "                task_config.name, # with the afinitiies\n",
    "                datasplit_config.name, # all the data sets we split (val and train)\n",
    "                architecture_config.name, # UNET arch\n",
    "                trainer_config.name, # the trainer\n",
    "            ]\n",
    "        )\n",
    "        + f\"__test_{i}\",\n",
    "        task_config=task_config,\n",
    "        datasplit_config=datasplit_config,\n",
    "        architecture_config=architecture_config,\n",
    "        trainer_config=trainer_config,\n",
    "        num_iterations=iterations,\n",
    "        validation_interval=validation_interval,\n",
    "        repetition=i,\n",
    "        start_config=start_config,\n",
    "    )\n",
    "    config_store.store_run_config(run_config)\n",
    "#\"dacapo run -r {run_config.name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([219200,  16000,  42400])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finetuned_3d_lsdaffs_plasmodesmata_upsample-unet_default_v2__1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_config.name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize run before train: https://github.com/janelia-cellmap/ml_experiments/blob/main/scripts/visualize_pipeline.py\n",
    "creates a neuroglancer view, of your training samples. hitting \"t\" refreshes to a new example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python ~/Programming/ml_experiments/scripts/visualize_pipeline.py visualize-pipeline -r finetuned_3d_lsdaffs_nuclearpores_upsample-unet_default_v2__1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for now i manually created a file in ~/Programming/ml_experiments/configs/cellmap/runs/NP_test/runs.yaml which contains the run names then i changed to the ml_experiments directory and activate the `cellmap_experiments` dir. then i ran `python scripts/submit.py run -r configs/cellmap/runs/NP_test/runs.yaml -b cellmap -q gpu_t4 -n 10`. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Note"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had to change to `affs.astype(np.float64)` in line 49 /groups/scicompsoft/home/ackermand/Programming/dacapo/dacapo/experiments/tasks/post_processors/watershed_post_processor.py\", line 48, in process\n",
    "\n",
    "otherwise got this error:\n",
    "TypeError: argument 'affinities': type mismatch:\n",
    " from=float32, to=float64\n",
    "\n",
    "also had to add flattening and reshapping during remap in line 69 in same file:\n",
    "`segmentation = npi.remap(segmentation.flatten(), filtered_fragments, replace).reshape(segmentation.shape)`\n",
    "\n",
    "otherwise got error:\n",
    "TypeError: '<' not supported between instances of 'int' and 'bytes'\n",
    "\n",
    "Also had to change a lot in `/groups/scicompsoft/home/ackermand/Programming/dacapo/dacapo/validate.py` and `/groups/scicompsoft/home/ackermand/Programming/dacapo/dacapo/evaluate.py` because previously it would determine the best validation trial as being when a parameter setting produced better results than its previous best. This means that even if parameter_id = 0 was bad, as long as it was better than parameter_id=0 from all previous validations, then it would overwrite the best. I changed it so that the overall best for the metric, eg. `voi` is calculated first, and the best validation set is only overwritten if it is the overall best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numcodecs.gzip import GZip\n",
    "import zarr\n",
    "\n",
    "store = zarr.N5Store(\"./test.n5\")\n",
    "zarr_root = zarr.group(store=store)\n",
    "ds = zarr_root.create_dataset(\n",
    "        overwrite=True,\n",
    "        name=\"test\",\n",
    "        dtype='u1',\n",
    "        shape=zarr_file[dataset].shape,\n",
    "        chunks=128,\n",
    "        write_empty_chunks=False,\n",
    "        compressor=GZip(level=6),\n",
    "    )\n",
    "attributes = ds.attrs\n",
    "attributes[\"pixelResolution\"] = {\n",
    "    \"dimensions\": 3 * [8],\n",
    "    \"unit\": \"nm\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'bytes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/plasmodesmata_dacapo/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'bytes'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     values \u001b[39m=\u001b[39m replace\n\u001b[1;32m     14\u001b[0m \u001b[39m#idx = indices(keys, input.flatten(), missing='mask')\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m segmentation \u001b[39m=\u001b[39m npi\u001b[39m.\u001b[39;49mremap(segmentation, keys, values)\u001b[39m.\u001b[39mreshape(segmentation\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/plasmodesmata_dacapo/lib/python3.10/site-packages/numpy_indexed/arraysetops.py:195\u001b[0m, in \u001b[0;36mremap\u001b[0;34m(input, keys, values, missing, inplace)\u001b[0m\n\u001b[1;32m    193\u001b[0m values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(values)\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m missing \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 195\u001b[0m     idx \u001b[39m=\u001b[39m indices(keys, \u001b[39minput\u001b[39;49m, missing\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmask\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    196\u001b[0m     mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlogical_not(idx\u001b[39m.\u001b[39mmask)\n\u001b[1;32m    197\u001b[0m     idx \u001b[39m=\u001b[39m idx\u001b[39m.\u001b[39mdata\n",
      "File \u001b[0;32m~/miniconda3/envs/plasmodesmata_dacapo/lib/python3.10/site-packages/numpy_indexed/arraysetops.py:152\u001b[0m, in \u001b[0;36mindices\u001b[0;34m(this, that, axis, missing)\u001b[0m\n\u001b[1;32m    149\u001b[0m that \u001b[39m=\u001b[39m as_index(that, axis\u001b[39m=\u001b[39maxis, base\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, lex_as_struct\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    151\u001b[0m \u001b[39m# use raw private keys here, rather than public unpacked keys\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m insertion \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msearchsorted(this\u001b[39m.\u001b[39;49m_keys, that\u001b[39m.\u001b[39;49m_keys, sorter\u001b[39m=\u001b[39;49mthis\u001b[39m.\u001b[39;49msorter, side\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    153\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtake(this\u001b[39m.\u001b[39msorter, insertion, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mclip\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[39mif\u001b[39;00m missing \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msearchsorted\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/plasmodesmata_dacapo/lib/python3.10/site-packages/numpy/core/fromnumeric.py:1413\u001b[0m, in \u001b[0;36msearchsorted\u001b[0;34m(a, v, side, sorter)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_searchsorted_dispatcher)\n\u001b[1;32m   1346\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msearchsorted\u001b[39m(a, v, side\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m, sorter\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1347\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m \u001b[39m    Find indices where elements should be inserted to maintain order.\u001b[39;00m\n\u001b[1;32m   1349\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1411\u001b[0m \n\u001b[1;32m   1412\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1413\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39msearchsorted\u001b[39;49m\u001b[39m'\u001b[39;49m, v, side\u001b[39m=\u001b[39;49mside, sorter\u001b[39m=\u001b[39;49msorter)\n",
      "File \u001b[0;32m~/miniconda3/envs/plasmodesmata_dacapo/lib/python3.10/site-packages/numpy/core/fromnumeric.py:66\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/plasmodesmata_dacapo/lib/python3.10/site-packages/numpy/core/fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     wrap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(asarray(obj), method)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m wrap:\n\u001b[1;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, mu\u001b[39m.\u001b[39mndarray):\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'bytes'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy_indexed as npi\n",
    "import numpy as np\n",
    "from numpy_indexed.funcs import *\n",
    "from numpy_indexed.index import *\n",
    "from builtins import *\n",
    "from numpy_indexed.arraysetops import indices\n",
    "\n",
    "with open('remap.pkl', 'rb') as f:\n",
    "    segmentation, filtered_fragments, replace = pickle.load(f)\n",
    "    input=segmentation\n",
    "    keys = filtered_fragments\n",
    "    values = replace\n",
    "#idx = indices(keys, input.flatten(), missing='mask')\n",
    "segmentation = npi.remap(segmentation, keys, values).reshape(segmentation.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. symlink to default directory `/nrs/cellmap/data/` as seen in `ml_experiments/configs/yamls/constants.yaml`\n",
    "2. add `nuclearpores` to `ml_experiments/configs/yamls/targets/instance_seg.yaml`\n",
    "3. copy `ml_experiments/configs/cellmap/predictions/jrc_mu-liver-zon-1/2023-02-10.yaml` to `ml_experiments/configs/cellmap/predictions/NP_test/2023-05-17.yaml` and update accordingly.\n",
    "4. Try to predict using this: `python scripts/submit.py predict -p configs/cellmap/predictions/NP_test/2023-05-17.yaml -w 60`, based on this region [this region](http://renderer.int.janelia.org:8080/ng/#!%7B%22dimensions%22:%7B%22x%22:%5B1e-9%2C%22m%22%5D%2C%22y%22:%5B1e-9%2C%22m%22%5D%2C%22z%22:%5B1e-9%2C%22m%22%5D%7D%2C%22position%22:%5B228016.65625%2C14467.8486328125%2C58427.31640625%5D%2C%22crossSectionOrientation%22:%5B0%2C1%2C0%2C0%5D%2C%22crossSectionScale%22:9.803848825583122%2C%22projectionOrientation%22:%5B-0.33944520354270935%2C-0.9385530948638916%2C-0.019331367686390877%2C-0.05934092774987221%5D%2C%22projectionScale%22:6636.598844056%2C%22layers%22:%5B%7B%22type%22:%22image%22%2C%22source%22:%22n5://http://renderer.int.janelia.org:8080/n5_sources/stern/jrc_22ak351-leaf-3m.n5/em/fibsem-uint8%22%2C%22tab%22:%22source%22%2C%22shaderControls%22:%7B%22normalized%22:%7B%22range%22:%5B40%2C140%5D%7D%7D%2C%22crossSectionRenderScale%22:0.12964438055577399%2C%22name%22:%22fibsem-uint8%22%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%5B%22n5://http://cellmap-vm1.int.janelia.org/nrs/ackermand/cellmap/leaf-gall/jrc_22ak351-leaf-3m.n5/plasmodesmata_column_cells/%22%2C%22precomputed://http://cellmap-vm1.int.janelia.org/nrs/ackermand/meshes/multiresolution/leaf-gall/jrc_22ak351-leaf-3m/plasmodesmata_column_cells/multires%22%5D%2C%22tab%22:%22segments%22%2C%22selectedAlpha%22:0.43%2C%22meshSilhouetteRendering%22:2.6%2C%22segmentDefaultColor%22:%22#9900ff%22%2C%22name%22:%22plasmodesmata_column_cells%22%2C%22visible%22:false%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%5B%22n5://http://cellmap-vm1.int.janelia.org/nrs/ackermand/cellmap/leaf-gall/jrc_22ak351-leaf-3m.n5/plasmodesmata_column_target_cells%22%2C%22precomputed://http://cellmap-vm1.int.janelia.org/nrs/ackermand/meshes/multiresolution/leaf-gall/jrc_22ak351-leaf-3m/plasmodesmata_column_target_cells/multires%22%5D%2C%22tab%22:%22source%22%2C%22selectedAlpha%22:0.2%2C%22segmentDefaultColor%22:%22#1fffb4%22%2C%22name%22:%22plasmodesmata_column_target_cells%22%7D%2C%7B%22type%22:%22annotation%22%2C%22source%22:%7B%22url%22:%22local://annotations%22%2C%22transform%22:%7B%22outputDimensions%22:%7B%22x%22:%5B1e-9%2C%22m%22%5D%2C%22y%22:%5B1e-9%2C%22m%22%5D%2C%22z%22:%5B1e-9%2C%22m%22%5D%7D%2C%22inputDimensions%22:%7B%220%22:%5B8e-9%2C%22m%22%5D%2C%221%22:%5B8e-9%2C%22m%22%5D%2C%222%22:%5B8e-9%2C%22m%22%5D%7D%7D%7D%2C%22tool%22:%22annotateLine%22%2C%22tab%22:%22source%22%2C%22annotations%22:%5B%5D%2C%22shader%22:%22#uicontrol%20float%20lineWidth%20slider%28min=1%2C%20max=50%2C%20step=1%2C%20default=10%29%5Cn#uicontrol%20vec3%20color%20color%28default=%5C%22white%5C%22%29%5Cn%5Cnvoid%20main%28%29%20%7B%5Cn%20%20setLineWidth%28lineWidth%29%3B%5Cn%20%20setColor%28color%29%3B%5Cn%7D%5Cn%5Cn%22%2C%22shaderControls%22:%7B%22color%22:%22#ff0000%22%7D%2C%22name%22:%22annotations%22%7D%2C%7B%22type%22:%22annotation%22%2C%22source%22:%22precomputed://https://cellmap-vm1.int.janelia.org/dm11/ackermand/neuroglancer_annotations/20230510_114340%22%2C%22tab%22:%22source%22%2C%22annotationColor%22:%22#8b8b23%22%2C%22shader%22:%22#uicontrol%20float%20lineWidth%20slider%28min=1%2C%20max=50%2C%20step=1%2C%20default=10%29%5Cn#uicontrol%20vec3%20color%20color%28default=%5C%22white%5C%22%29%5Cn%5Cnvoid%20main%28%29%20%7B%5Cn%20%20setLineWidth%28lineWidth%29%3B%5Cn%20%20setColor%28color%29%3B%5Cn%7D%5Cn%5Cn%22%2C%22shaderControls%22:%7B%22color%22:%22#ff0000%22%7D%2C%22name%22:%22saved_annotations%22%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%7B%22url%22:%22n5://http://cellmap-vm1.int.janelia.org/nrs/ackermand/cellmap/leaf-gall/jrc_22ak351-leaf-3m.n5/validation_crop/%22%2C%22transform%22:%7B%22matrix%22:%5B%5B1%2C0%2C0%2C219200%5D%2C%5B0%2C1%2C0%2C16000%5D%2C%5B0%2C0%2C1%2C42400%5D%5D%2C%22outputDimensions%22:%7B%22x%22:%5B1e-9%2C%22m%22%5D%2C%22y%22:%5B1e-9%2C%22m%22%5D%2C%22z%22:%5B1e-9%2C%22m%22%5D%7D%7D%2C%22subsources%22:%7B%22default%22:true%2C%22bounds%22:true%7D%2C%22enableDefaultSubsources%22:false%7D%2C%22tab%22:%22source%22%2C%22name%22:%22validation_crop%22%7D%5D%2C%22showSlices%22:false%2C%22selectedLayer%22:%7B%22visible%22:true%2C%22layer%22:%22validation_crop%22%7D%2C%22layout%22:%224panel%22%2C%22statistics%22:%7B%22visible%22:true%7D%2C%22selection%22:%7B%22layers%22:%7B%22annotations%22:%7B%22annotationId%22:%22df5661d17178a2ccd1624582136e59c925677961%22%2C%22annotationSource%22:0%2C%22annotationSubsource%22:%22default%22%7D%7D%7D%7D)\n",
    "\n",
    "Once we have lsds we need to do affinities\n",
    "\n",
    "1. `python scripts/post_processing_david/02_extract_fragments_blockwise.py`\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3] [4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "prediction_data = yaml.safe_load(Path(\"/groups/scicompsoft/home/ackermand/Programming/ml_experiments/configs/cellmap/predictions/pd_test/2023-05-17.yaml\").open(\"r\").read())\n",
    "for matrix in prediction_data[\"predictions\"]:\n",
    "    offset, shape = matrix.get(\"roi\", (None, None))\n",
    "    print(offset,shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scratchspace"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.5 -0.5 -0.5]\n",
      "  [-0.5 -0.5 -0.5]\n",
      "  [-0.5 -0.5 -0.5]]\n",
      "\n",
      " [[-0.5 -0.5 -0.5]\n",
      "  [-0.5 -0.5 -0.5]\n",
      "  [-0.5 -0.5 -0.5]]] [[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "import mwatershed\n",
    "import numpy as  np\n",
    "offsets = [(0, 1), (1, 0)]\n",
    "affinities = (\n",
    "    np.array(\n",
    "        #[[[0, 1, 0], [0, 1, 0], [0, 1, 0]], \n",
    "        # [[0, 0, 0], [1, 1, 1], [0, 0, 0]]],\n",
    "        [[[0, 0, 0], [0, 0, 0], [0, 0, 0]], \n",
    "        [[0, 0, 0], [0, 0, 0], [0, 0, 0]]],\n",
    "        dtype=float,\n",
    "    )\n",
    "    - 0.5\n",
    ")\n",
    "# 9 nodes. connecting edges:\n",
    "# 2-3, 5-6, 8-9, 4-7, 5-8, 6-9\n",
    "# components: [(1,),(2,3),(4,7),(5,6,8,9)]\n",
    "\n",
    "components = mwatershed.agglom(affinities, offsets)\n",
    "print(affinities,components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 1]\n",
      "  [1 7]]\n",
      "\n",
      " [[1 7]\n",
      "  [7 7]]]\n"
     ]
    }
   ],
   "source": [
    "import mwatershed\n",
    "offsets = [(0, 0, 1), (0, 1, 0), (1, 0, 0)]\n",
    "affinities = (\n",
    "    np.array(\n",
    "        [\n",
    "            [[[1, 0], [0, 0]], [[0, 0], [1, 0]]],\n",
    "            [[[1, 0], [0, 0]], [[0, 1], [0, 0]]],\n",
    "            [[[1, 0], [0, 1]], [[0, 0], [0, 0]]],\n",
    "        ],\n",
    "        dtype=float,\n",
    "    )\n",
    "    - 0.5\n",
    ")\n",
    "# 8 nodes. connecting edges:\n",
    "# 1-2, 1-3, 1-7, 4-8, 6-8, 7-8\n",
    "# components: [(1,2,3,7),(4,6,7,8)]\n",
    "\n",
    "components = mwatershed.agglom(affinities, offsets)\n",
    "print(components)\n",
    "#assert set(np.unique(components)) == set([1, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:/groups/scicompsoft/home/ackermand/Programming/dacapo/dacapo/experiments/starts/start.py:Error(s) in loading state_dict for Model:\n",
      "\tMissing key(s) in state_dict: \"architecture.unet.l_conv.0.conv_pass.0.weight\", \"architecture.unet.l_conv.0.conv_pass.0.bias\", \"architecture.unet.l_conv.0.conv_pass.2.weight\", \"architecture.unet.l_conv.0.conv_pass.2.bias\", \"architecture.unet.l_conv.1.conv_pass.0.weight\", \"architecture.unet.l_conv.1.conv_pass.0.bias\", \"architecture.unet.l_conv.1.conv_pass.2.weight\", \"architecture.unet.l_conv.1.conv_pass.2.bias\", \"architecture.unet.l_conv.2.conv_pass.0.weight\", \"architecture.unet.l_conv.2.conv_pass.0.bias\", \"architecture.unet.l_conv.2.conv_pass.2.weight\", \"architecture.unet.l_conv.2.conv_pass.2.bias\", \"architecture.unet.l_conv.3.conv_pass.0.weight\", \"architecture.unet.l_conv.3.conv_pass.0.bias\", \"architecture.unet.l_conv.3.conv_pass.2.weight\", \"architecture.unet.l_conv.3.conv_pass.2.bias\", \"architecture.unet.r_up.0.0.up.1.weight\", \"architecture.unet.r_up.0.0.up.1.bias\", \"architecture.unet.r_up.0.1.up.1.weight\", \"architecture.unet.r_up.0.1.up.1.bias\", \"architecture.unet.r_up.0.2.up.1.weight\", \"architecture.unet.r_up.0.2.up.1.bias\", \"architecture.unet.r_conv.0.0.conv_pass.0.weight\", \"architecture.unet.r_conv.0.0.conv_pass.0.bias\", \"architecture.unet.r_conv.0.0.conv_pass.2.weight\", \"architecture.unet.r_conv.0.0.conv_pass.2.bias\", \"architecture.unet.r_conv.0.1.conv_pass.0.weight\", \"architecture.unet.r_conv.0.1.conv_pass.0.bias\", \"architecture.unet.r_conv.0.1.conv_pass.2.weight\", \"architecture.unet.r_conv.0.1.conv_pass.2.bias\", \"architecture.unet.r_conv.0.2.conv_pass.0.weight\", \"architecture.unet.r_conv.0.2.conv_pass.0.bias\", \"architecture.unet.r_conv.0.2.conv_pass.2.weight\", \"architecture.unet.r_conv.0.2.conv_pass.2.bias\", \"chain.0.unet.l_conv.0.conv_pass.0.weight\", \"chain.0.unet.l_conv.0.conv_pass.0.bias\", \"chain.0.unet.l_conv.0.conv_pass.2.weight\", \"chain.0.unet.l_conv.0.conv_pass.2.bias\", \"chain.0.unet.l_conv.1.conv_pass.0.weight\", \"chain.0.unet.l_conv.1.conv_pass.0.bias\", \"chain.0.unet.l_conv.1.conv_pass.2.weight\", \"chain.0.unet.l_conv.1.conv_pass.2.bias\", \"chain.0.unet.l_conv.2.conv_pass.0.weight\", \"chain.0.unet.l_conv.2.conv_pass.0.bias\", \"chain.0.unet.l_conv.2.conv_pass.2.weight\", \"chain.0.unet.l_conv.2.conv_pass.2.bias\", \"chain.0.unet.l_conv.3.conv_pass.0.weight\", \"chain.0.unet.l_conv.3.conv_pass.0.bias\", \"chain.0.unet.l_conv.3.conv_pass.2.weight\", \"chain.0.unet.l_conv.3.conv_pass.2.bias\", \"chain.0.unet.r_up.0.0.up.1.weight\", \"chain.0.unet.r_up.0.0.up.1.bias\", \"chain.0.unet.r_up.0.1.up.1.weight\", \"chain.0.unet.r_up.0.1.up.1.bias\", \"chain.0.unet.r_up.0.2.up.1.weight\", \"chain.0.unet.r_up.0.2.up.1.bias\", \"chain.0.unet.r_conv.0.0.conv_pass.0.weight\", \"chain.0.unet.r_conv.0.0.conv_pass.0.bias\", \"chain.0.unet.r_conv.0.0.conv_pass.2.weight\", \"chain.0.unet.r_conv.0.0.conv_pass.2.bias\", \"chain.0.unet.r_conv.0.1.conv_pass.0.weight\", \"chain.0.unet.r_conv.0.1.conv_pass.0.bias\", \"chain.0.unet.r_conv.0.1.conv_pass.2.weight\", \"chain.0.unet.r_conv.0.1.conv_pass.2.bias\", \"chain.0.unet.r_conv.0.2.conv_pass.0.weight\", \"chain.0.unet.r_conv.0.2.conv_pass.0.bias\", \"chain.0.unet.r_conv.0.2.conv_pass.2.weight\", \"chain.0.unet.r_conv.0.2.conv_pass.2.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"architecture.unet.0.l_conv.0.conv_pass.0.weight\", \"architecture.unet.0.l_conv.0.conv_pass.0.bias\", \"architecture.unet.0.l_conv.0.conv_pass.2.weight\", \"architecture.unet.0.l_conv.0.conv_pass.2.bias\", \"architecture.unet.0.l_conv.1.conv_pass.0.weight\", \"architecture.unet.0.l_conv.1.conv_pass.0.bias\", \"architecture.unet.0.l_conv.1.conv_pass.2.weight\", \"architecture.unet.0.l_conv.1.conv_pass.2.bias\", \"architecture.unet.0.l_conv.2.conv_pass.0.weight\", \"architecture.unet.0.l_conv.2.conv_pass.0.bias\", \"architecture.unet.0.l_conv.2.conv_pass.2.weight\", \"architecture.unet.0.l_conv.2.conv_pass.2.bias\", \"architecture.unet.0.l_conv.3.conv_pass.0.weight\", \"architecture.unet.0.l_conv.3.conv_pass.0.bias\", \"architecture.unet.0.l_conv.3.conv_pass.2.weight\", \"architecture.unet.0.l_conv.3.conv_pass.2.bias\", \"architecture.unet.0.r_up.0.0.up.1.weight\", \"architecture.unet.0.r_up.0.0.up.1.bias\", \"architecture.unet.0.r_up.0.1.up.1.weight\", \"architecture.unet.0.r_up.0.1.up.1.bias\", \"architecture.unet.0.r_up.0.2.up.1.weight\", \"architecture.unet.0.r_up.0.2.up.1.bias\", \"architecture.unet.0.r_conv.0.0.conv_pass.0.weight\", \"architecture.unet.0.r_conv.0.0.conv_pass.0.bias\", \"architecture.unet.0.r_conv.0.0.conv_pass.2.weight\", \"architecture.unet.0.r_conv.0.0.conv_pass.2.bias\", \"architecture.unet.0.r_conv.0.1.conv_pass.0.weight\", \"architecture.unet.0.r_conv.0.1.conv_pass.0.bias\", \"architecture.unet.0.r_conv.0.1.conv_pass.2.weight\", \"architecture.unet.0.r_conv.0.1.conv_pass.2.bias\", \"architecture.unet.0.r_conv.0.2.conv_pass.0.weight\", \"architecture.unet.0.r_conv.0.2.conv_pass.0.bias\", \"architecture.unet.0.r_conv.0.2.conv_pass.2.weight\", \"architecture.unet.0.r_conv.0.2.conv_pass.2.bias\", \"architecture.unet.1.up.1.weight\", \"architecture.unet.1.up.1.bias\", \"architecture.unet.2.conv_pass.0.weight\", \"architecture.unet.2.conv_pass.0.bias\", \"architecture.unet.2.conv_pass.2.weight\", \"architecture.unet.2.conv_pass.2.bias\", \"chain.0.unet.0.l_conv.0.conv_pass.0.weight\", \"chain.0.unet.0.l_conv.0.conv_pass.0.bias\", \"chain.0.unet.0.l_conv.0.conv_pass.2.weight\", \"chain.0.unet.0.l_conv.0.conv_pass.2.bias\", \"chain.0.unet.0.l_conv.1.conv_pass.0.weight\", \"chain.0.unet.0.l_conv.1.conv_pass.0.bias\", \"chain.0.unet.0.l_conv.1.conv_pass.2.weight\", \"chain.0.unet.0.l_conv.1.conv_pass.2.bias\", \"chain.0.unet.0.l_conv.2.conv_pass.0.weight\", \"chain.0.unet.0.l_conv.2.conv_pass.0.bias\", \"chain.0.unet.0.l_conv.2.conv_pass.2.weight\", \"chain.0.unet.0.l_conv.2.conv_pass.2.bias\", \"chain.0.unet.0.l_conv.3.conv_pass.0.weight\", \"chain.0.unet.0.l_conv.3.conv_pass.0.bias\", \"chain.0.unet.0.l_conv.3.conv_pass.2.weight\", \"chain.0.unet.0.l_conv.3.conv_pass.2.bias\", \"chain.0.unet.0.r_up.0.0.up.1.weight\", \"chain.0.unet.0.r_up.0.0.up.1.bias\", \"chain.0.unet.0.r_up.0.1.up.1.weight\", \"chain.0.unet.0.r_up.0.1.up.1.bias\", \"chain.0.unet.0.r_up.0.2.up.1.weight\", \"chain.0.unet.0.r_up.0.2.up.1.bias\", \"chain.0.unet.0.r_conv.0.0.conv_pass.0.weight\", \"chain.0.unet.0.r_conv.0.0.conv_pass.0.bias\", \"chain.0.unet.0.r_conv.0.0.conv_pass.2.weight\", \"chain.0.unet.0.r_conv.0.0.conv_pass.2.bias\", \"chain.0.unet.0.r_conv.0.1.conv_pass.0.weight\", \"chain.0.unet.0.r_conv.0.1.conv_pass.0.bias\", \"chain.0.unet.0.r_conv.0.1.conv_pass.2.weight\", \"chain.0.unet.0.r_conv.0.1.conv_pass.2.bias\", \"chain.0.unet.0.r_conv.0.2.conv_pass.0.weight\", \"chain.0.unet.0.r_conv.0.2.conv_pass.0.bias\", \"chain.0.unet.0.r_conv.0.2.conv_pass.2.weight\", \"chain.0.unet.0.r_conv.0.2.conv_pass.2.bias\", \"chain.0.unet.1.up.1.weight\", \"chain.0.unet.1.up.1.bias\", \"chain.0.unet.2.conv_pass.0.weight\", \"chain.0.unet.2.conv_pass.0.bias\", \"chain.0.unet.2.conv_pass.2.weight\", \"chain.0.unet.2.conv_pass.2.bias\". \n",
      "\tsize mismatch for prediction_head.weight: copying a param with shape torch.Size([14, 72, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([19, 72, 1, 1, 1]).\n",
      "\tsize mismatch for prediction_head.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([19]).\n",
      "\tsize mismatch for chain.1.weight: copying a param with shape torch.Size([14, 72, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([19, 72, 1, 1, 1]).\n",
      "\tsize mismatch for chain.1.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([19]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.154080601777265\n"
     ]
    }
   ],
   "source": [
    "from dacapo.predict import predict\n",
    "from dacapo.compute_context import LocalTorch, ComputeContext\n",
    "from dacapo.experiments import Run, ValidationIterationScores\n",
    "from dacapo.experiments.datasplits.datasets.arrays import ZarrArray\n",
    "from dacapo.store import (\n",
    "    create_array_store,\n",
    "    create_config_store,\n",
    "    create_stats_store,\n",
    "    create_weights_store,\n",
    ")\n",
    "\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "run_name = \"finetuned_3d_lsdaffs_nuclearpores_upsample-unet_default_v2__0\"\n",
    "\n",
    "config_store = create_config_store()\n",
    "run_config = config_store.retrieve_run_config(run_name)\n",
    "run = Run(run_config)\n",
    "\n",
    "# read in previous training/validation stats\n",
    "\n",
    "stats_store = create_stats_store()\n",
    "run.training_stats = stats_store.retrieve_training_stats(run_name)\n",
    "run.validation_scores.scores = stats_store.retrieve_validation_iteration_scores(\n",
    "    run_name\n",
    ")\n",
    "\n",
    "evaluator = run.task.evaluator\n",
    "evaluator.set_best(run.validation_scores)\n",
    "\n",
    "#weights_store = create_weights_store()\n",
    "#print(weights_store.retrieve_best(run_name, \"voi\", \"val\"))\n",
    "\n",
    "# Initialize the evaluator with the best scores seen so far\n",
    "#evaluator.set_best(run.validation_scores)\n",
    "\n",
    "from dacapo.experiments.tasks.evaluators import InstanceEvaluationScores\n",
    "from dacapo.experiments.datasplits.datasets import Dataset\n",
    "\n",
    "scores = InstanceEvaluationScores()\n",
    "for dataset,_,_ in evaluator.best_scores.keys():\n",
    "    break\n",
    "overall_best_score = evaluator.get_overall_best(dataset, \"voi_merge\", scores)\n",
    "print(overall_best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = zarr.open('test.n5', mode='w')\n",
    "z[1,2,3]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.zeros([128*3]*3)\n",
    "starts = np.array([100.5,20,5])\n",
    "ends = np.array([150,40.5,20])\n",
    "radius = 3\n",
    "index_iterable = np.ndindex(*arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p = np.indices(arr.shape).reshape((arr.size,3))\n",
    "\n",
    "in_cylinder(p,a,b,r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simplest way to generate the rasterized cylinders would be to open each annotation and writing out annotations in corresponding chunks, then we only have to do ~1900 iterations. and can just write out to appropriate chunks. can also read if the chunk already exists so we can write multiple annotations to same chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'blockSize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39marray(zarr_file[dataset]\u001b[39m.\u001b[39;49mattrs\u001b[39m.\u001b[39;49masdict()[\u001b[39m\"\u001b[39;49m\u001b[39mblockSize\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'blockSize'"
     ]
    }
   ],
   "source": [
    "np.array(zarr_file[dataset].attrs.asdict()[\"blockSize\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11301, 6464, 32690)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zarr_file[dataset].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Volume (nm^3)')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(\"/nrs/cellmap/ackermand/cellmap/analysisResults/jrc_mus-liver-zon-1/nucleus.csv\")\n",
    "plt.hist(df[\"Volume (nm^3)\"],bins=100)\n",
    "plt.semilogy()\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Volume (nm^3)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sum(df[\"Volume (nm^3)\"]>0.25e13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "uint64 uint64 uint64\n"
     ]
    }
   ],
   "source": [
    "import numpy_indexed as npi\n",
    "import numpy as np\n",
    "a=np.array([1,2],dtype=np.uint64)\n",
    "b=np.array([1,2],dtype=np.uint64)\n",
    "c=np.array([1,2],dtype=np.uint64)\n",
    "\n",
    "print(npi.remap(a,b,c))\n",
    "print(a.dtype,b.dtype,c.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1]]],\n",
       "\n",
       "\n",
       "       [[[-1]]],\n",
       "\n",
       "\n",
       "       [[[-1]]],\n",
       "\n",
       "\n",
       "       [[[ 1]]],\n",
       "\n",
       "\n",
       "       [[[ 1]]],\n",
       "\n",
       "\n",
       "       [[[ 1]]],\n",
       "\n",
       "\n",
       "       [[[ 1]]],\n",
       "\n",
       "\n",
       "       [[[ 1]]],\n",
       "\n",
       "\n",
       "       [[[ 1]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "adjacent_edge_bias = -1\n",
    "lr_edge_bias = 1\n",
    "offsets = [\n",
    "                (1, 0, 0),\n",
    "                (0, 1, 0),\n",
    "                (0, 0, 1),\n",
    "                (3, 0, 0),\n",
    "                (0, 3, 0),\n",
    "                (0, 0, 3),\n",
    "                (9, 0, 0),\n",
    "                (0, 9, 0),\n",
    "                (0, 0, 9),\n",
    "            ]\n",
    "shift = np.array(\n",
    "    [adjacent_edge_bias if max(offset) <= 1 else lr_edge_bias for offset in offsets]\n",
    ").reshape((-1, *((1,) * (len((3, 136, 136, 121)) - 1))))\n",
    "shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:/groups/scicompsoft/home/ackermand/Programming/dacapo/dacapo/experiments/starts/start.py:Error(s) in loading state_dict for Model:\n",
      "\tMissing key(s) in state_dict: \"architecture.unet.l_conv.0.conv_pass.0.weight\", \"architecture.unet.l_conv.0.conv_pass.0.bias\", \"architecture.unet.l_conv.0.conv_pass.2.weight\", \"architecture.unet.l_conv.0.conv_pass.2.bias\", \"architecture.unet.l_conv.1.conv_pass.0.weight\", \"architecture.unet.l_conv.1.conv_pass.0.bias\", \"architecture.unet.l_conv.1.conv_pass.2.weight\", \"architecture.unet.l_conv.1.conv_pass.2.bias\", \"architecture.unet.l_conv.2.conv_pass.0.weight\", \"architecture.unet.l_conv.2.conv_pass.0.bias\", \"architecture.unet.l_conv.2.conv_pass.2.weight\", \"architecture.unet.l_conv.2.conv_pass.2.bias\", \"architecture.unet.l_conv.3.conv_pass.0.weight\", \"architecture.unet.l_conv.3.conv_pass.0.bias\", \"architecture.unet.l_conv.3.conv_pass.2.weight\", \"architecture.unet.l_conv.3.conv_pass.2.bias\", \"architecture.unet.r_up.0.0.up.1.weight\", \"architecture.unet.r_up.0.0.up.1.bias\", \"architecture.unet.r_up.0.1.up.1.weight\", \"architecture.unet.r_up.0.1.up.1.bias\", \"architecture.unet.r_up.0.2.up.1.weight\", \"architecture.unet.r_up.0.2.up.1.bias\", \"architecture.unet.r_conv.0.0.conv_pass.0.weight\", \"architecture.unet.r_conv.0.0.conv_pass.0.bias\", \"architecture.unet.r_conv.0.0.conv_pass.2.weight\", \"architecture.unet.r_conv.0.0.conv_pass.2.bias\", \"architecture.unet.r_conv.0.1.conv_pass.0.weight\", \"architecture.unet.r_conv.0.1.conv_pass.0.bias\", \"architecture.unet.r_conv.0.1.conv_pass.2.weight\", \"architecture.unet.r_conv.0.1.conv_pass.2.bias\", \"architecture.unet.r_conv.0.2.conv_pass.0.weight\", \"architecture.unet.r_conv.0.2.conv_pass.0.bias\", \"architecture.unet.r_conv.0.2.conv_pass.2.weight\", \"architecture.unet.r_conv.0.2.conv_pass.2.bias\", \"chain.0.unet.l_conv.0.conv_pass.0.weight\", \"chain.0.unet.l_conv.0.conv_pass.0.bias\", \"chain.0.unet.l_conv.0.conv_pass.2.weight\", \"chain.0.unet.l_conv.0.conv_pass.2.bias\", \"chain.0.unet.l_conv.1.conv_pass.0.weight\", \"chain.0.unet.l_conv.1.conv_pass.0.bias\", \"chain.0.unet.l_conv.1.conv_pass.2.weight\", \"chain.0.unet.l_conv.1.conv_pass.2.bias\", \"chain.0.unet.l_conv.2.conv_pass.0.weight\", \"chain.0.unet.l_conv.2.conv_pass.0.bias\", \"chain.0.unet.l_conv.2.conv_pass.2.weight\", \"chain.0.unet.l_conv.2.conv_pass.2.bias\", \"chain.0.unet.l_conv.3.conv_pass.0.weight\", \"chain.0.unet.l_conv.3.conv_pass.0.bias\", \"chain.0.unet.l_conv.3.conv_pass.2.weight\", \"chain.0.unet.l_conv.3.conv_pass.2.bias\", \"chain.0.unet.r_up.0.0.up.1.weight\", \"chain.0.unet.r_up.0.0.up.1.bias\", \"chain.0.unet.r_up.0.1.up.1.weight\", \"chain.0.unet.r_up.0.1.up.1.bias\", \"chain.0.unet.r_up.0.2.up.1.weight\", \"chain.0.unet.r_up.0.2.up.1.bias\", \"chain.0.unet.r_conv.0.0.conv_pass.0.weight\", \"chain.0.unet.r_conv.0.0.conv_pass.0.bias\", \"chain.0.unet.r_conv.0.0.conv_pass.2.weight\", \"chain.0.unet.r_conv.0.0.conv_pass.2.bias\", \"chain.0.unet.r_conv.0.1.conv_pass.0.weight\", \"chain.0.unet.r_conv.0.1.conv_pass.0.bias\", \"chain.0.unet.r_conv.0.1.conv_pass.2.weight\", \"chain.0.unet.r_conv.0.1.conv_pass.2.bias\", \"chain.0.unet.r_conv.0.2.conv_pass.0.weight\", \"chain.0.unet.r_conv.0.2.conv_pass.0.bias\", \"chain.0.unet.r_conv.0.2.conv_pass.2.weight\", \"chain.0.unet.r_conv.0.2.conv_pass.2.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"architecture.unet.0.l_conv.0.conv_pass.0.weight\", \"architecture.unet.0.l_conv.0.conv_pass.0.bias\", \"architecture.unet.0.l_conv.0.conv_pass.2.weight\", \"architecture.unet.0.l_conv.0.conv_pass.2.bias\", \"architecture.unet.0.l_conv.1.conv_pass.0.weight\", \"architecture.unet.0.l_conv.1.conv_pass.0.bias\", \"architecture.unet.0.l_conv.1.conv_pass.2.weight\", \"architecture.unet.0.l_conv.1.conv_pass.2.bias\", \"architecture.unet.0.l_conv.2.conv_pass.0.weight\", \"architecture.unet.0.l_conv.2.conv_pass.0.bias\", \"architecture.unet.0.l_conv.2.conv_pass.2.weight\", \"architecture.unet.0.l_conv.2.conv_pass.2.bias\", \"architecture.unet.0.l_conv.3.conv_pass.0.weight\", \"architecture.unet.0.l_conv.3.conv_pass.0.bias\", \"architecture.unet.0.l_conv.3.conv_pass.2.weight\", \"architecture.unet.0.l_conv.3.conv_pass.2.bias\", \"architecture.unet.0.r_up.0.0.up.1.weight\", \"architecture.unet.0.r_up.0.0.up.1.bias\", \"architecture.unet.0.r_up.0.1.up.1.weight\", \"architecture.unet.0.r_up.0.1.up.1.bias\", \"architecture.unet.0.r_up.0.2.up.1.weight\", \"architecture.unet.0.r_up.0.2.up.1.bias\", \"architecture.unet.0.r_conv.0.0.conv_pass.0.weight\", \"architecture.unet.0.r_conv.0.0.conv_pass.0.bias\", \"architecture.unet.0.r_conv.0.0.conv_pass.2.weight\", \"architecture.unet.0.r_conv.0.0.conv_pass.2.bias\", \"architecture.unet.0.r_conv.0.1.conv_pass.0.weight\", \"architecture.unet.0.r_conv.0.1.conv_pass.0.bias\", \"architecture.unet.0.r_conv.0.1.conv_pass.2.weight\", \"architecture.unet.0.r_conv.0.1.conv_pass.2.bias\", \"architecture.unet.0.r_conv.0.2.conv_pass.0.weight\", \"architecture.unet.0.r_conv.0.2.conv_pass.0.bias\", \"architecture.unet.0.r_conv.0.2.conv_pass.2.weight\", \"architecture.unet.0.r_conv.0.2.conv_pass.2.bias\", \"architecture.unet.1.up.1.weight\", \"architecture.unet.1.up.1.bias\", \"architecture.unet.2.conv_pass.0.weight\", \"architecture.unet.2.conv_pass.0.bias\", \"architecture.unet.2.conv_pass.2.weight\", \"architecture.unet.2.conv_pass.2.bias\", \"chain.0.unet.0.l_conv.0.conv_pass.0.weight\", \"chain.0.unet.0.l_conv.0.conv_pass.0.bias\", \"chain.0.unet.0.l_conv.0.conv_pass.2.weight\", \"chain.0.unet.0.l_conv.0.conv_pass.2.bias\", \"chain.0.unet.0.l_conv.1.conv_pass.0.weight\", \"chain.0.unet.0.l_conv.1.conv_pass.0.bias\", \"chain.0.unet.0.l_conv.1.conv_pass.2.weight\", \"chain.0.unet.0.l_conv.1.conv_pass.2.bias\", \"chain.0.unet.0.l_conv.2.conv_pass.0.weight\", \"chain.0.unet.0.l_conv.2.conv_pass.0.bias\", \"chain.0.unet.0.l_conv.2.conv_pass.2.weight\", \"chain.0.unet.0.l_conv.2.conv_pass.2.bias\", \"chain.0.unet.0.l_conv.3.conv_pass.0.weight\", \"chain.0.unet.0.l_conv.3.conv_pass.0.bias\", \"chain.0.unet.0.l_conv.3.conv_pass.2.weight\", \"chain.0.unet.0.l_conv.3.conv_pass.2.bias\", \"chain.0.unet.0.r_up.0.0.up.1.weight\", \"chain.0.unet.0.r_up.0.0.up.1.bias\", \"chain.0.unet.0.r_up.0.1.up.1.weight\", \"chain.0.unet.0.r_up.0.1.up.1.bias\", \"chain.0.unet.0.r_up.0.2.up.1.weight\", \"chain.0.unet.0.r_up.0.2.up.1.bias\", \"chain.0.unet.0.r_conv.0.0.conv_pass.0.weight\", \"chain.0.unet.0.r_conv.0.0.conv_pass.0.bias\", \"chain.0.unet.0.r_conv.0.0.conv_pass.2.weight\", \"chain.0.unet.0.r_conv.0.0.conv_pass.2.bias\", \"chain.0.unet.0.r_conv.0.1.conv_pass.0.weight\", \"chain.0.unet.0.r_conv.0.1.conv_pass.0.bias\", \"chain.0.unet.0.r_conv.0.1.conv_pass.2.weight\", \"chain.0.unet.0.r_conv.0.1.conv_pass.2.bias\", \"chain.0.unet.0.r_conv.0.2.conv_pass.0.weight\", \"chain.0.unet.0.r_conv.0.2.conv_pass.0.bias\", \"chain.0.unet.0.r_conv.0.2.conv_pass.2.weight\", \"chain.0.unet.0.r_conv.0.2.conv_pass.2.bias\", \"chain.0.unet.1.up.1.weight\", \"chain.0.unet.1.up.1.bias\", \"chain.0.unet.2.conv_pass.0.weight\", \"chain.0.unet.2.conv_pass.0.bias\", \"chain.0.unet.2.conv_pass.2.weight\", \"chain.0.unet.2.conv_pass.2.bias\". \n",
      "\tsize mismatch for prediction_head.weight: copying a param with shape torch.Size([14, 72, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([19, 72, 1, 1, 1]).\n",
      "\tsize mismatch for prediction_head.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([19]).\n",
      "\tsize mismatch for chain.1.weight: copying a param with shape torch.Size([14, 72, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([19, 72, 1, 1, 1]).\n",
      "\tsize mismatch for chain.1.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([19]).\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Predicting with input size (2304, 2304, 2304), output size (864, 864, 864), gt_padding (128, 128, 192)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m output_size \u001b[39m=\u001b[39m output_voxel_size \u001b[39m*\u001b[39m model\u001b[39m.\u001b[39mcompute_output_shape(input_shape)[\u001b[39m1\u001b[39m]\n\u001b[1;32m     46\u001b[0m gt_padding \u001b[39m=\u001b[39m (output_size \u001b[39m-\u001b[39m validation_dataset\u001b[39m.\u001b[39mgt\u001b[39m.\u001b[39mroi\u001b[39m.\u001b[39mshape) \u001b[39m%\u001b[39m output_size\n\u001b[0;32m---> 47\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredicting with input size \u001b[39m\u001b[39m{\u001b[39;00minput_size\u001b[39m}\u001b[39;00m\u001b[39m, output size \u001b[39m\u001b[39m{\u001b[39;00moutput_size\u001b[39m}\u001b[39;00m\u001b[39m, gt_padding \u001b[39m\u001b[39m{\u001b[39;00mgt_padding\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[39m# calculate input and output rois\u001b[39;00m\n\u001b[1;32m     50\u001b[0m context \u001b[39m=\u001b[39m (input_size \u001b[39m-\u001b[39m output_size) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n",
      "\u001b[0;31mException\u001b[0m: Predicting with input size (2304, 2304, 2304), output size (864, 864, 864), gt_padding (128, 128, 192)"
     ]
    }
   ],
   "source": [
    "from dacapo.store.create_store import create_config_store,create_config_store,create_weights_store\n",
    "from dacapo.experiments import Run\n",
    "\n",
    "import daisy\n",
    "from funlib.persistence import open_ds, prepare_ds\n",
    "from funlib.geometry import Coordinate,Roi\n",
    "\n",
    "import click\n",
    "import numpy as np\n",
    "\n",
    "import subprocess\n",
    "import logging\n",
    "from dacapo.predict import predict\n",
    "from dacapo.store.local_array_store import LocalArrayIdentifier\n",
    "from dacapo.compute_context import LocalTorch\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from dacapo.experiments.datasplits.datasets.arrays import ZarrArray\n",
    "from dacapo.experiments.tasks.post_processors.watershed_post_processor_parameters import WatershedPostProcessorParameters\n",
    "\n",
    "\n",
    "run_name = \"finetuned_3d_lsdaffs_nuclearpores_upsample-unet_default_v2__0\"\n",
    "config_store = create_config_store()\n",
    "run_config = config_store.retrieve_run_config(run_name)\n",
    "\n",
    "config_store = create_config_store()\n",
    "run_config = config_store.retrieve_run_config(run_name)\n",
    "run = Run(run_config)\n",
    "\n",
    "# create weights store and read weights\n",
    "weights_store = create_weights_store()\n",
    "weights = weights_store.retrieve_weights(run, 165000)\n",
    "weights_store._load_best(run, \"val/voi\")\n",
    "#run.model.load_state_dict(weights.model)\n",
    "\n",
    "for validation_dataset in run.datasplit.validate:\n",
    "    output_roi = validation_dataset.gt.roi\n",
    "    model = run.model\n",
    "    raw_array = validation_dataset.raw\n",
    "\n",
    "    input_voxel_size = Coordinate(raw_array.voxel_size)\n",
    "    output_voxel_size = model.scale(input_voxel_size)\n",
    "    input_shape = Coordinate(model.eval_input_shape)\n",
    "    input_size = input_voxel_size * input_shape\n",
    "    output_size = output_voxel_size * model.compute_output_shape(input_shape)[1]\n",
    "    gt_padding = (output_size - validation_dataset.gt.roi.shape) % output_size\n",
    "    raise Exception(f\"Predicting with input size {input_size}, output size {output_size}, gt_padding {gt_padding}\")\n",
    "    # calculate input and output rois\n",
    "\n",
    "    context = (input_size - output_size) / 2\n",
    "    if output_roi is None:\n",
    "        input_roi = raw_array.roi\n",
    "        output_roi = input_roi.grow(-context, -context)\n",
    "    else:\n",
    "        input_roi = output_roi.grow(context, context)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    run.model.eval()\n",
    "    prediction_array_identifier = LocalArrayIdentifier(Path(\"/groups/cellmap/cellmap/ackermand/Programming/nuclearpores_dacapo/temp.n5\"), \"pred_original_outputsize\")\n",
    "    predict(\n",
    "            run.model,\n",
    "            validation_dataset.raw,\n",
    "            prediction_array_identifier,\n",
    "            compute_context=LocalTorch(),\n",
    "            output_roi=validation_dataset.gt.roi,#Roi((42400,16000,219200),(108*8,108*8,108*8)),#\n",
    "        )\n",
    "\n",
    "    # post_processor = run.task.post_processor\n",
    "    # post_processor.set_prediction(prediction_array_identifier)\n",
    "\n",
    "\n",
    "    # output_array_identifier = LocalArrayIdentifier(Path(\"/groups/cellmap/cellmap/ackermand/Programming/nuclearpores_dacapo/temp.n5\"), \"output\")\n",
    "    \n",
    "    # prediction_array = ZarrArray.open_from_array_identifier(\n",
    "    #         prediction_array_identifier\n",
    "    #     )\n",
    "    # output_array = ZarrArray.create_from_array_identifier(\n",
    "    #         output_array_identifier,\n",
    "    #         [axis for axis in prediction_array.axes if axis != \"c\"],\n",
    "    #         prediction_array.roi,\n",
    "    #         None,\n",
    "    #         prediction_array.voxel_size,\n",
    "    #         np.uint64,\n",
    "    # )\n",
    "    # post_processed_array = post_processor.process(\n",
    "    #                  WatershedPostProcessorParameters(id=2, bias=0.5), output_array_identifier\n",
    "    #             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/scicompsoft/home/ackermand/miniconda3/envs/cellmap_experiments/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:/groups/scicompsoft/home/ackermand/Programming/dacapo/dacapo/experiments/starts/start.py:Error(s) in loading state_dict for Model:\n",
      "\tMissing key(s) in state_dict: \"architecture.unet.l_conv.0.conv_pass.0.weight\", \"architecture.unet.l_conv.0.conv_pass.0.bias\", \"architecture.unet.l_conv.0.conv_pass.2.weight\", \"architecture.unet.l_conv.0.conv_pass.2.bias\", \"architecture.unet.l_conv.1.conv_pass.0.weight\", \"architecture.unet.l_conv.1.conv_pass.0.bias\", \"architecture.unet.l_conv.1.conv_pass.2.weight\", \"architecture.unet.l_conv.1.conv_pass.2.bias\", \"architecture.unet.l_conv.2.conv_pass.0.weight\", \"architecture.unet.l_conv.2.conv_pass.0.bias\", \"architecture.unet.l_conv.2.conv_pass.2.weight\", \"architecture.unet.l_conv.2.conv_pass.2.bias\", \"architecture.unet.l_conv.3.conv_pass.0.weight\", \"architecture.unet.l_conv.3.conv_pass.0.bias\", \"architecture.unet.l_conv.3.conv_pass.2.weight\", \"architecture.unet.l_conv.3.conv_pass.2.bias\", \"architecture.unet.r_up.0.0.up.1.weight\", \"architecture.unet.r_up.0.0.up.1.bias\", \"architecture.unet.r_up.0.1.up.1.weight\", \"architecture.unet.r_up.0.1.up.1.bias\", \"architecture.unet.r_up.0.2.up.1.weight\", \"architecture.unet.r_up.0.2.up.1.bias\", \"architecture.unet.r_conv.0.0.conv_pass.0.weight\", \"architecture.unet.r_conv.0.0.conv_pass.0.bias\", \"architecture.unet.r_conv.0.0.conv_pass.2.weight\", \"architecture.unet.r_conv.0.0.conv_pass.2.bias\", \"architecture.unet.r_conv.0.1.conv_pass.0.weight\", \"architecture.unet.r_conv.0.1.conv_pass.0.bias\", \"architecture.unet.r_conv.0.1.conv_pass.2.weight\", \"architecture.unet.r_conv.0.1.conv_pass.2.bias\", \"architecture.unet.r_conv.0.2.conv_pass.0.weight\", \"architecture.unet.r_conv.0.2.conv_pass.0.bias\", \"architecture.unet.r_conv.0.2.conv_pass.2.weight\", \"architecture.unet.r_conv.0.2.conv_pass.2.bias\", \"chain.0.unet.l_conv.0.conv_pass.0.weight\", \"chain.0.unet.l_conv.0.conv_pass.0.bias\", \"chain.0.unet.l_conv.0.conv_pass.2.weight\", \"chain.0.unet.l_conv.0.conv_pass.2.bias\", \"chain.0.unet.l_conv.1.conv_pass.0.weight\", \"chain.0.unet.l_conv.1.conv_pass.0.bias\", \"chain.0.unet.l_conv.1.conv_pass.2.weight\", \"chain.0.unet.l_conv.1.conv_pass.2.bias\", \"chain.0.unet.l_conv.2.conv_pass.0.weight\", \"chain.0.unet.l_conv.2.conv_pass.0.bias\", \"chain.0.unet.l_conv.2.conv_pass.2.weight\", \"chain.0.unet.l_conv.2.conv_pass.2.bias\", \"chain.0.unet.l_conv.3.conv_pass.0.weight\", \"chain.0.unet.l_conv.3.conv_pass.0.bias\", \"chain.0.unet.l_conv.3.conv_pass.2.weight\", \"chain.0.unet.l_conv.3.conv_pass.2.bias\", \"chain.0.unet.r_up.0.0.up.1.weight\", \"chain.0.unet.r_up.0.0.up.1.bias\", \"chain.0.unet.r_up.0.1.up.1.weight\", \"chain.0.unet.r_up.0.1.up.1.bias\", \"chain.0.unet.r_up.0.2.up.1.weight\", \"chain.0.unet.r_up.0.2.up.1.bias\", \"chain.0.unet.r_conv.0.0.conv_pass.0.weight\", \"chain.0.unet.r_conv.0.0.conv_pass.0.bias\", \"chain.0.unet.r_conv.0.0.conv_pass.2.weight\", \"chain.0.unet.r_conv.0.0.conv_pass.2.bias\", \"chain.0.unet.r_conv.0.1.conv_pass.0.weight\", \"chain.0.unet.r_conv.0.1.conv_pass.0.bias\", \"chain.0.unet.r_conv.0.1.conv_pass.2.weight\", \"chain.0.unet.r_conv.0.1.conv_pass.2.bias\", \"chain.0.unet.r_conv.0.2.conv_pass.0.weight\", \"chain.0.unet.r_conv.0.2.conv_pass.0.bias\", \"chain.0.unet.r_conv.0.2.conv_pass.2.weight\", \"chain.0.unet.r_conv.0.2.conv_pass.2.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"architecture.unet.0.l_conv.0.conv_pass.0.weight\", \"architecture.unet.0.l_conv.0.conv_pass.0.bias\", \"architecture.unet.0.l_conv.0.conv_pass.2.weight\", \"architecture.unet.0.l_conv.0.conv_pass.2.bias\", \"architecture.unet.0.l_conv.1.conv_pass.0.weight\", \"architecture.unet.0.l_conv.1.conv_pass.0.bias\", \"architecture.unet.0.l_conv.1.conv_pass.2.weight\", \"architecture.unet.0.l_conv.1.conv_pass.2.bias\", \"architecture.unet.0.l_conv.2.conv_pass.0.weight\", \"architecture.unet.0.l_conv.2.conv_pass.0.bias\", \"architecture.unet.0.l_conv.2.conv_pass.2.weight\", \"architecture.unet.0.l_conv.2.conv_pass.2.bias\", \"architecture.unet.0.l_conv.3.conv_pass.0.weight\", \"architecture.unet.0.l_conv.3.conv_pass.0.bias\", \"architecture.unet.0.l_conv.3.conv_pass.2.weight\", \"architecture.unet.0.l_conv.3.conv_pass.2.bias\", \"architecture.unet.0.r_up.0.0.up.1.weight\", \"architecture.unet.0.r_up.0.0.up.1.bias\", \"architecture.unet.0.r_up.0.1.up.1.weight\", \"architecture.unet.0.r_up.0.1.up.1.bias\", \"architecture.unet.0.r_up.0.2.up.1.weight\", \"architecture.unet.0.r_up.0.2.up.1.bias\", \"architecture.unet.0.r_conv.0.0.conv_pass.0.weight\", \"architecture.unet.0.r_conv.0.0.conv_pass.0.bias\", \"architecture.unet.0.r_conv.0.0.conv_pass.2.weight\", \"architecture.unet.0.r_conv.0.0.conv_pass.2.bias\", \"architecture.unet.0.r_conv.0.1.conv_pass.0.weight\", \"architecture.unet.0.r_conv.0.1.conv_pass.0.bias\", \"architecture.unet.0.r_conv.0.1.conv_pass.2.weight\", \"architecture.unet.0.r_conv.0.1.conv_pass.2.bias\", \"architecture.unet.0.r_conv.0.2.conv_pass.0.weight\", \"architecture.unet.0.r_conv.0.2.conv_pass.0.bias\", \"architecture.unet.0.r_conv.0.2.conv_pass.2.weight\", \"architecture.unet.0.r_conv.0.2.conv_pass.2.bias\", \"architecture.unet.1.up.1.weight\", \"architecture.unet.1.up.1.bias\", \"architecture.unet.2.conv_pass.0.weight\", \"architecture.unet.2.conv_pass.0.bias\", \"architecture.unet.2.conv_pass.2.weight\", \"architecture.unet.2.conv_pass.2.bias\", \"chain.0.unet.0.l_conv.0.conv_pass.0.weight\", \"chain.0.unet.0.l_conv.0.conv_pass.0.bias\", \"chain.0.unet.0.l_conv.0.conv_pass.2.weight\", \"chain.0.unet.0.l_conv.0.conv_pass.2.bias\", \"chain.0.unet.0.l_conv.1.conv_pass.0.weight\", \"chain.0.unet.0.l_conv.1.conv_pass.0.bias\", \"chain.0.unet.0.l_conv.1.conv_pass.2.weight\", \"chain.0.unet.0.l_conv.1.conv_pass.2.bias\", \"chain.0.unet.0.l_conv.2.conv_pass.0.weight\", \"chain.0.unet.0.l_conv.2.conv_pass.0.bias\", \"chain.0.unet.0.l_conv.2.conv_pass.2.weight\", \"chain.0.unet.0.l_conv.2.conv_pass.2.bias\", \"chain.0.unet.0.l_conv.3.conv_pass.0.weight\", \"chain.0.unet.0.l_conv.3.conv_pass.0.bias\", \"chain.0.unet.0.l_conv.3.conv_pass.2.weight\", \"chain.0.unet.0.l_conv.3.conv_pass.2.bias\", \"chain.0.unet.0.r_up.0.0.up.1.weight\", \"chain.0.unet.0.r_up.0.0.up.1.bias\", \"chain.0.unet.0.r_up.0.1.up.1.weight\", \"chain.0.unet.0.r_up.0.1.up.1.bias\", \"chain.0.unet.0.r_up.0.2.up.1.weight\", \"chain.0.unet.0.r_up.0.2.up.1.bias\", \"chain.0.unet.0.r_conv.0.0.conv_pass.0.weight\", \"chain.0.unet.0.r_conv.0.0.conv_pass.0.bias\", \"chain.0.unet.0.r_conv.0.0.conv_pass.2.weight\", \"chain.0.unet.0.r_conv.0.0.conv_pass.2.bias\", \"chain.0.unet.0.r_conv.0.1.conv_pass.0.weight\", \"chain.0.unet.0.r_conv.0.1.conv_pass.0.bias\", \"chain.0.unet.0.r_conv.0.1.conv_pass.2.weight\", \"chain.0.unet.0.r_conv.0.1.conv_pass.2.bias\", \"chain.0.unet.0.r_conv.0.2.conv_pass.0.weight\", \"chain.0.unet.0.r_conv.0.2.conv_pass.0.bias\", \"chain.0.unet.0.r_conv.0.2.conv_pass.2.weight\", \"chain.0.unet.0.r_conv.0.2.conv_pass.2.bias\", \"chain.0.unet.1.up.1.weight\", \"chain.0.unet.1.up.1.bias\", \"chain.0.unet.2.conv_pass.0.weight\", \"chain.0.unet.2.conv_pass.0.bias\", \"chain.0.unet.2.conv_pass.2.weight\", \"chain.0.unet.2.conv_pass.2.bias\". \n",
      "\tsize mismatch for prediction_head.weight: copying a param with shape torch.Size([14, 72, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([19, 72, 1, 1, 1]).\n",
      "\tsize mismatch for prediction_head.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([19]).\n",
      "\tsize mismatch for chain.1.weight: copying a param with shape torch.Size([14, 72, 1, 1, 1]) from checkpoint, the shape in current model is torch.Size([19, 72, 1, 1, 1]).\n",
      "\tsize mismatch for chain.1.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([19]).\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Predicting with input size (2304, 2304, 2304), output size (864, 864, 864), gt_padding (128, 128, 192)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m output_size \u001b[39m=\u001b[39m output_voxel_size \u001b[39m*\u001b[39m model\u001b[39m.\u001b[39mcompute_output_shape(input_shape)[\u001b[39m1\u001b[39m]\n\u001b[1;32m     47\u001b[0m gt_padding \u001b[39m=\u001b[39m (output_size \u001b[39m-\u001b[39m validation_dataset\u001b[39m.\u001b[39mgt\u001b[39m.\u001b[39mroi\u001b[39m.\u001b[39mshape) \u001b[39m%\u001b[39m output_size\n\u001b[0;32m---> 48\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredicting with input size \u001b[39m\u001b[39m{\u001b[39;00minput_size\u001b[39m}\u001b[39;00m\u001b[39m, output size \u001b[39m\u001b[39m{\u001b[39;00moutput_size\u001b[39m}\u001b[39;00m\u001b[39m, gt_padding \u001b[39m\u001b[39m{\u001b[39;00mgt_padding\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[39m# calculate input and output rois\u001b[39;00m\n\u001b[1;32m     51\u001b[0m context \u001b[39m=\u001b[39m (input_size \u001b[39m-\u001b[39m output_size) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n",
      "\u001b[0;31mException\u001b[0m: Predicting with input size (2304, 2304, 2304), output size (864, 864, 864), gt_padding (128, 128, 192)"
     ]
    }
   ],
   "source": [
    "# for jan\n",
    "from dacapo.store.create_store import create_config_store,create_config_store,create_weights_store\n",
    "from dacapo.experiments import Run\n",
    "\n",
    "import daisy\n",
    "from funlib.persistence import open_ds, prepare_ds\n",
    "from funlib.geometry import Coordinate,Roi\n",
    "import numpy as np\n",
    "\n",
    "from dacapo.predict import predict\n",
    "from dacapo.store.local_array_store import LocalArrayIdentifier\n",
    "from dacapo.compute_context import LocalTorch\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from dacapo.experiments.tasks.post_processors.watershed_post_processor_parameters import WatershedPostProcessorParameters\n",
    "\n",
    "\n",
    "run_name = \"finetuned_3d_lsdaffs_nuclearpores_upsample-unet_default_v2__0\"\n",
    "config_store = create_config_store()\n",
    "run_config = config_store.retrieve_run_config(run_name)\n",
    "\n",
    "config_store = create_config_store()\n",
    "run_config = config_store.retrieve_run_config(run_name)\n",
    "run = Run(run_config)\n",
    "\n",
    "# create weights store and read weights\n",
    "weights_store = create_weights_store()\n",
    "weights = weights_store.retrieve_weights(run, 165000)\n",
    "weights_store._load_best(run, \"val/voi\")\n",
    "\n",
    "for validation_dataset in run.datasplit.validate:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    run.model.eval()\n",
    "    prediction_array_identifier = LocalArrayIdentifier(Path(\"/groups/cellmap/cellmap/ackermand/Programming/nuclearpores_dacapo/temp.n5\"), \"pred_original_outputsize\")\n",
    "    predict(\n",
    "            run.model,\n",
    "            validation_dataset.raw,\n",
    "            prediction_array_identifier,\n",
    "            compute_context=LocalTorch(),\n",
    "            output_roi=validation_dataset.gt.roi,#Roi((42400,16000,219200),(108*8,108*8,108*8)),#\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funlib.geometry import Coordinate, Roi\n",
    "val_input = validation_dataset.raw.__getitem__(input_roi)\n",
    "\n",
    "raw_dataset = open_ds(\"/nrs/cellmap/data/jrc_22ak351-leaf-3m/jrc_22ak351-leaf-3m.n5\", \"em/fibsem-uint8/s0\")\n",
    "shift = 0\n",
    "scale = 255\n",
    "raw_input = (\n",
    "                    raw_dataset.to_ndarray(\n",
    "                        roi=input_roi, fill_value=shift + scale\n",
    "                    ).astype(np.float32)\n",
    "                    - shift\n",
    "                ) / scale\n",
    "raw_input = np.expand_dims(raw_input, (0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can not downsample shape torch.Size([1, 72, 184, 184, 234]) with factor (3, 3, 3), mismatch in spatial dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m run\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(torch\u001b[39m.\u001b[39;49mfrom_numpy(raw_input)\u001b[39m.\u001b[39;49mfloat()\u001b[39m.\u001b[39;49mto( torch\u001b[39m.\u001b[39;49mdevice(\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)))\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()[\u001b[39m0\u001b[39m],\n",
      "File \u001b[0;32m~/Programming/dacapo/dacapo/experiments/model.py:44\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 44\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchain(x)\n\u001b[1;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_activation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_activation(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/cellmap_experiments/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/cellmap_experiments/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/cellmap_experiments/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Programming/dacapo/dacapo/experiments/architectures/cnnectome_unet.py:109\u001b[0m, in \u001b[0;36mCNNectomeUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munet(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/cellmap_experiments/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Programming/dacapo/dacapo/experiments/architectures/cnnectome_unet.py:373\u001b[0m, in \u001b[0;36mCNNectomeUNetModule.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 373\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrec_forward(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_levels \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m, x)\n\u001b[1;32m    375\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    376\u001b[0m         \u001b[39mreturn\u001b[39;00m y[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Programming/dacapo/dacapo/experiments/architectures/cnnectome_unet.py:360\u001b[0m, in \u001b[0;36mCNNectomeUNetModule.rec_forward\u001b[0;34m(self, level, f_in)\u001b[0m\n\u001b[1;32m    357\u001b[0m g_in \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml_down[i](f_left)\n\u001b[1;32m    359\u001b[0m \u001b[39m# nested levels\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m gs_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrec_forward(level \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m, g_in)\n\u001b[1;32m    362\u001b[0m \u001b[39m# up, concat, and crop\u001b[39;00m\n\u001b[1;32m    363\u001b[0m fs_right \u001b[39m=\u001b[39m [\n\u001b[1;32m    364\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr_up[h][i](gs_out[h], f_left) \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads)\n\u001b[1;32m    365\u001b[0m ]\n",
      "File \u001b[0;32m~/Programming/dacapo/dacapo/experiments/architectures/cnnectome_unet.py:357\u001b[0m, in \u001b[0;36mCNNectomeUNetModule.rec_forward\u001b[0;34m(self, level, f_in)\u001b[0m\n\u001b[1;32m    353\u001b[0m     fs_out \u001b[39m=\u001b[39m [f_left] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads\n\u001b[1;32m    355\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     \u001b[39m# down\u001b[39;00m\n\u001b[0;32m--> 357\u001b[0m     g_in \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml_down[i](f_left)\n\u001b[1;32m    359\u001b[0m     \u001b[39m# nested levels\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     gs_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_forward(level \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, g_in)\n",
      "File \u001b[0;32m~/miniconda3/envs/cellmap_experiments/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Programming/dacapo/dacapo/experiments/architectures/cnnectome_unet.py:439\u001b[0m, in \u001b[0;36mDownsample.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdims \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    438\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39msize()[\u001b[39m-\u001b[39md] \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample_factor[\u001b[39m-\u001b[39md] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 439\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    440\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCan not downsample shape \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m with factor \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, mismatch \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39min spatial dimension \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m             \u001b[39m%\u001b[39m (x\u001b[39m.\u001b[39msize(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample_factor, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdims \u001b[39m-\u001b[39m d)\n\u001b[1;32m    443\u001b[0m         )\n\u001b[1;32m    445\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can not downsample shape torch.Size([1, 72, 184, 184, 234]) with factor (3, 3, 3), mismatch in spatial dimension 1"
     ]
    }
   ],
   "source": [
    "model = run.model.to(torch.device(\"cpu\"))\n",
    "predictions = model.forward(torch.from_numpy(raw_input).float().to( torch.device(\"cpu\"))).detach().cpu().numpy()[0],\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(raw_input,val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = run.model.compute_output_shape(run.model.eval_input_shape)[1]*daisy.Coordinate((8,8,8))\n",
    "gt_padding = (output_size - daisy.Coordinate((1600,1600,2400))) % output_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16, 24)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_padding/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LocalArrayIdentifier(container=PosixPath('/nrs/cellmap/ackermand/cellmap_experiments/test/finetuned_3d_lsdaffs_plasmodesmata_upsample-unet_default_v2__0/validation.zarr'), dataset='inputs/val/raw'), LocalArrayIdentifier(container=PosixPath('/nrs/cellmap/ackermand/cellmap_experiments/test/finetuned_3d_lsdaffs_plasmodesmata_upsample-unet_default_v2__0/validation.zarr'), dataset='inputs/val/gt'))\n"
     ]
    }
   ],
   "source": [
    "from dacapo.store.create_store import create_array_store\n",
    "array_store = create_array_store()\n",
    "print(array_store.validation_input_arrays(run.name, validation_dataset.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Coordinate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 14\u001b[0m\n\u001b[1;32m      8\u001b[0m out_dataset \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtemp\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m channel \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     10\u001b[0m prepare_ds(\n\u001b[1;32m     11\u001b[0m     out_container,\n\u001b[1;32m     12\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mout_dataset\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mchannel\u001b[39m}\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m{\u001b[39;00maff_or_lsd\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     total_roi\u001b[39m=\u001b[39mRoi([\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m128\u001b[39m,\u001b[39m128\u001b[39m,\u001b[39m128\u001b[39m]),\n\u001b[0;32m---> 14\u001b[0m     voxel_size\u001b[39m=\u001b[39mCoordinate([\u001b[39m8\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m8\u001b[39m]),\n\u001b[1;32m     15\u001b[0m     write_size\u001b[39m=\u001b[39mCoordinate([\u001b[39m64\u001b[39m,\u001b[39m64\u001b[39m,\u001b[39m64\u001b[39m]),\n\u001b[1;32m     16\u001b[0m     dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32,\n\u001b[1;32m     17\u001b[0m     num_channels\u001b[39m=\u001b[39mn_channels,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m root \u001b[39m=\u001b[39m zarr\u001b[39m.\u001b[39mopen(out_container, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m ds \u001b[39m=\u001b[39m root[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mout_dataset\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mchannel\u001b[39m}\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m{\u001b[39;00maff_or_lsd\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Coordinate' is not defined"
     ]
    }
   ],
   "source": [
    "from funlib.geometry import Roi\n",
    "import zarr\n",
    "neighborhood = run_config.task_config.neighborhood\n",
    "num_channels = run.model.num_out_channels\n",
    "\n",
    "for aff_or_lsd, n_channels in zip([\"affs\", \"lsds\"], [len(neighborhood), num_channels-len(neighborhood)]):\n",
    "    out_container = \"temp.n5\"\n",
    "    out_dataset = \"temp\"\n",
    "    channel = 0\n",
    "    prepare_ds(\n",
    "        out_container,\n",
    "        f\"{out_dataset}/{channel}__{aff_or_lsd}\",\n",
    "        total_roi=Roi([0,0,0],[128,128,128]),\n",
    "        voxel_size=Coordinate([8,8,8]),\n",
    "        write_size=Coordinate([64,64,64]),\n",
    "        dtype=np.float32,\n",
    "        num_channels=n_channels,\n",
    "    )\n",
    "    root = zarr.open(out_container, mode=\"a\")\n",
    "    ds = root[f\"{out_dataset}/{channel}__{aff_or_lsd}\"]\n",
    "    if out_container.endswith(\".zarr\"):\n",
    "        ds.attrs[\"offsets\"] = [n[::-1] for n in neighborhood]\n",
    "    else:\n",
    "        ds.attrs[\"offsets\"] = neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'funlib.geometry.coordinate.Coordinate'>\n"
     ]
    }
   ],
   "source": [
    "neighborhood = run_config.task_config.neighborhood\n",
    "print(type(neighborhood),type(neighborhood[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 200, 200, 300)\n",
      "(9, 200, 200, 300)\n",
      "(200, 200, 300)\n"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "out_container = \"/nrs/cellmap/ackermand/predictions/jrc_22ak351-leaf-3m/jrc_22ak351-leaf-3m.n5\"\n",
    "root = zarr.open(out_container, mode=\"r\")\n",
    "ds = root[f\"predictions/2023-05-24/nuclearpores_affs_lsds/0__affs\"]\n",
    "print(ds.shape)\n",
    "\n",
    "from funlib.persistence import open_ds\n",
    "print(open_ds(out_container,\"predictions/2023-05-24/nuclearpores_affs_lsds/0__affs\").shape)\n",
    "\n",
    "#plt.imshow(np.mean(ds[:,:,:,0],axis=0),vmax=0.5)\n",
    "out_container = \"/nrs/cellmap/ackermand/cellmap_experiments/test/finetuned_3d_lsdaffs_nuclearpores_pseudorandom_training_centers_maxshift_10_upsample-unet_default_v2__0/validation.zarr\"\n",
    "# root = zarr.open(out_container, mode=\"r\")\n",
    "#print(root[f\"val/voi\"].shape)\n",
    "print(open_ds(out_container, \"val/voi\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22947/1346163204.py:42: DeprecationWarning: Please use `mean` from the `scipy.ndimage` namespace, the `scipy.ndimage.measurements` namespace is deprecated.\n",
      "  fragment_ids, measurements.mean(average_affs, fragments_data, fragment_ids)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb41feddc30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from funlib.geometry import Roi\n",
    "import zarr\n",
    "import mwatershed as mws\n",
    "from funlib.segment.arrays import relabel, replace_values\n",
    "from funlib.persistence import open_ds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import measurements\n",
    "\n",
    "# densely annotated validation region:\n",
    "offset = np.array([27400, 2000, 5300])\n",
    "dimensions = np.array([300, 200, 200])\n",
    "zarr_file = zarr.open(f\"/nrs/stern/em_data/jrc_22ak351-leaf-3m/jrc_22ak351-leaf-3m.n5\", mode=\"r\")\n",
    "dataset = \"em/fibsem-uint8/s0\"\n",
    "resolution = np.array(zarr_file[dataset].attrs.asdict()[\"transform\"][\"scale\"])\n",
    "validation_roi = Roi(offset[::-1]*resolution, dimensions[::-1]*resolution)\n",
    "\n",
    "affs = open_ds(\"/nrs/cellmap/ackermand/predictions/jrc_22ak351-leaf-3m/jrc_22ak351-leaf-3m.n5\",\"/predictions/2023-05-24/nuclearpores_affs_lsds/0__affs\")\n",
    "offsets = affs.data.attrs[\"affs_offsets\"]\n",
    "affs = open_ds(\"/groups/cellmap/cellmap/ackermand/Programming/nuclearpores_dacapo/temp.n5\",\"pred\")\n",
    "#offsets = [offset[::-1] for offset in offsets]\n",
    "#offsets=[offsets[i] for i in range(8,-1,-1)]\n",
    "offsets = offsets[:]\n",
    "affs = affs.intersect(validation_roi)\n",
    "affs.materialize()\n",
    "affs.data=affs.data[:9].astype(np.float64)\n",
    "\n",
    "filter_fragments = 0.5\n",
    "fragments_data = mws.agglom(\n",
    "        affs.data - filter_fragments,# + shift + random_noise + smoothed_affs,\n",
    "        offsets=offsets,\n",
    "    )\n",
    "prev_high_mean = 0\n",
    "if filter_fragments > 0:\n",
    "        average_affs = np.mean(affs.data, axis=0)\n",
    "\n",
    "        filtered_fragments = []\n",
    "\n",
    "        fragment_ids = np.unique(fragments_data)\n",
    "\n",
    "        for fragment, mean in zip(\n",
    "            fragment_ids, measurements.mean(average_affs, fragments_data, fragment_ids)\n",
    "        ):\n",
    "            if mean < filter_fragments:\n",
    "                filtered_fragments.append(fragment)\n",
    "            if mean>filter_fragments:\n",
    "                #print(fragment,np.sum(fragments_data == fragment))\n",
    "                prev_high_mean=mean\n",
    "\n",
    "        filtered_fragments = np.array(filtered_fragments, dtype=fragments_data.dtype)\n",
    "        replace = np.zeros_like(filtered_fragments)\n",
    "        replace_values(fragments_data, filtered_fragments, replace, inplace=True)\n",
    "plt.imshow(fragments_data[:,:,150],interpolation=\"none\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=uint64)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(fragments_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7feefebbd7e0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(fragments_data[:,:,120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mimshow(affs\u001b[39m.\u001b[39;49mdata[\u001b[39m6\u001b[39;49m,:,:,\u001b[39m64\u001b[39;49m])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for axis 0 with size 6"
     ]
    }
   ],
   "source": [
    "plt.imshow(affs.data[6,:,:,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LocalArrayIdentifier(container=PosixPath('/nrs/cellmap/ackermand/cellmap_experiments/test/finetuned_3d_lsdaffs_plasmodesmata_upsample-unet_default_v2__0/validation.zarr'), dataset='inputs/val/raw'),\n",
       " LocalArrayIdentifier(container=PosixPath('/nrs/cellmap/ackermand/cellmap_experiments/test/finetuned_3d_lsdaffs_plasmodesmata_upsample-unet_default_v2__0/validation.zarr'), dataset='inputs/val/gt'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dacapo.store import create_array_store\n",
    "array_store = create_array_store()\n",
    "array_store.validation_input_arrays(run.name, validation_dataset.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plasmodesmata_dacapo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
